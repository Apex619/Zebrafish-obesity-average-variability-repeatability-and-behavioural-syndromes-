---
title: "Personality"
author: "Hamza"
date: "12/02/2020"
output:
  html_document: default
  pdf_document: default
editor_options: 
  chunk_output_type: console
---


### Load packages
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#checks for installation and loads packages
pacman::p_load(lmerTest,ggThemeAssist,rptR,lme4,readxl, tidyr, dplyr, magrittr, lubridate, stringr, purrr,
               sjPlot,ggplot2,lubridate,wesanderson,ggbeeswarm,emmeans,patchwork,viridis,nlme,Rmisc,ggpubr,
               stargazer, brms, MCMCglmm)

# Load custom function to extract data 
source("../Scripts/functions_repeatability.R")
source("../Scripts/functions_personality.R")

```

### Import and subset data

First, we select a stimulus, which we want all the data for. Then with the function, we filter which videos have that stimulus in the first, second, third and fourth phase (via the time). Then we join all to create one dataset of that stimulus.
```{r}
Personality <- read.csv("./Data/Personality/ALL.csv")

# ROSE Q: have you tidied personality data to remove trials that were affected by covers falling down, etc.?
to_check <- Personality[Personality$Notes!="",] # check these ones

#HAMZA A: Apologies for the confusion. Those with the note "RE-RUN..." were fish that had to be re-run due to issues in a previous trial. Those fish are fine. Notes with a delay in time were also accounted for in Ethovision (by creating a unique setting for time). The other trials have been excluded. 

# ROSE request: fix mixing data for trial info
to_fix <- Personality[Personality$Date==""|Personality$Fish_ID=="",] # need date to know the age of the fish

# HAMZA A: Dates have been added. Sorry, again this was due to re-exporting from Ethovision and I forgot to add in certain details for the trial list. 


#Gathering all Social Data 

filter_etho(Personality, c("A","C","D","E","G","M"), ("6-9")) -> Social_Phase_1
filter_etho(Personality, c("J","K","L","P","U","X"), ("13-16")) -> Social_Phase_2
filter_etho(Personality, c("H","I","R","S","T","W"), ("20-23")) -> Social_Phase_3
filter_etho(Personality, c("B","F","N","O","Q","V"), ("27-30")) -> Social_Phase_4

Social_ALL <- bind_rows(Social_Phase_1,Social_Phase_2, Social_Phase_3, Social_Phase_4)



#Gathering all Predator Data

filter_etho(Personality, c("F","K","O","T","W","X"), ("6-9")) -> Predator_Phase_1
filter_etho(Personality, c("E","G","N","Q","R","S"), ("13-16")) -> Predator_Phase_2
filter_etho(Personality, c("B","C","M","P","U","V"), ("20-23")) -> Predator_Phase_3
filter_etho(Personality, c("A","D","H","I","J","L"), ("27-30")) -> Predator_Phase_4

Predator_ALL <- bind_rows(Predator_Phase_1,Predator_Phase_2, Predator_Phase_3, Predator_Phase_4)





#Gathering all Novel Data


filter_etho(Personality, c("B","H","J","N","P","R"), ("6-9")) -> Novel_Phase_1
filter_etho(Personality, c("A","I","M","O","V","W"), ("13-16")) -> Novel_Phase_2
filter_etho(Personality, c("D","F","G","L","Q","X"), ("20-23")) -> Novel_Phase_3
filter_etho(Personality, c("C","E","K","S","T","U"), ("27-30")) -> Novel_Phase_4

Novel_ALL <- bind_rows(Novel_Phase_1,Novel_Phase_2, Novel_Phase_3, Novel_Phase_4)





#Gathering all Aggression Data


filter_etho(Personality, c("I","L","Q","S","U","V"), ("6-9")) -> Aggression_Phase_1
filter_etho(Personality, c("B","C","D","F","H","T"), ("13-16")) -> Aggression_Phase_2
filter_etho(Personality, c("A","E","J","K","N","O"), ("20-23")) -> Aggression_Phase_3
filter_etho(Personality, c("G","M","P","R","W","X"), ("27-30")) -> Aggression_Phase_4

Aggression_ALL <- bind_rows(Aggression_Phase_1,Aggression_Phase_2, Aggression_Phase_3, Aggression_Phase_4)

#Subsetting data by control and treatment
Social_Control <- subset(Social_ALL, Social_ALL$Group == "Control") 
Social_Treatment <- subset(Social_ALL, Social_ALL$Group == "Treatment") 

Predator_Control <- subset(Predator_ALL, Predator_ALL$Group == "Control") 
Predator_Treatment <- subset(Predator_ALL, Predator_ALL$Group == "Treatment") 

Novel_Control <- subset(Novel_ALL, Novel_ALL$Group == "Control") 
Novel_Treatment <- subset(Novel_ALL, Novel_ALL$Group == "Treatment") 

Aggression_Control <- subset(Aggression_ALL, Aggression_ALL$Group == "Control") 
Aggression_Treatment <- subset(Aggression_ALL, Aggression_ALL$Group == "Treatment") 

# EXPLORATION DATA
# Acclimation <- read.csv("./Data/Personality/Acclimation.csv")
Post_assay <- read.csv("../Data/Personality/Post-assay.csv")
```

### ROSE: shorter code to Import and subset data   

```{r}
Personality <- read.csv("../Data/Personality/ALL.csv")

# making a column with a factor where the four levels correspond to the four phases
Personality$phase <-  factor(Personality$Time, levels = c("6-9", "13-16", "20-23", "27-30")) 

# making a list where each level of the list is a different phase
phases <- split(Personality, Personality$phase)

# function to apply to the four phases: 1, 2, 3, and 4
func_phase <- function(phase = 1){
    df <- phases[[phase]] # getting phase dataframe based on index (1-4)
    df$Behaviour <- df[,paste0("Phase",phase)] # getting columns that says which behaviour was in that phase
    df <- df[,!(names(df) %in% paste0("Phase", 1:4))] # removing the now-redunant Phase1,...,Phase4 columns
    return(df) # return dataframe
}

# applying function, returning a list of four dataframes
Personality_list <- lapply(1:4, function(x) func_phase(x))
Personality_df <- bind_rows(Personality_list) # stakes dataframe on top of each other

Aggression_ALL <- Personality_df[Personality_df$Behaviour == "Aggression",]
Novel_ALL <- Personality_df[Personality_df$Behaviour == "Novel",]
Predator_ALL <- Personality_df[Personality_df$Behaviour == "Predator",]
Social_ALL <- Personality_df[Personality_df$Behaviour == "Social",]

#Subsetting data by control and treatment
Social_Control <- subset(Social_ALL, Social_ALL$Group == "Control") 
Social_Treatment <- subset(Social_ALL, Social_ALL$Group == "Treatment") 

Predator_Control <- subset(Predator_ALL, Predator_ALL$Group == "Control") 
Predator_Treatment <- subset(Predator_ALL, Predator_ALL$Group == "Treatment") 

Novel_Control <- subset(Novel_ALL, Novel_ALL$Group == "Control") 
Novel_Treatment <- subset(Novel_ALL, Novel_ALL$Group == "Treatment") 

Aggression_Control <- subset(Aggression_ALL, Aggression_ALL$Group == "Control") 
Aggression_Treatment <- subset(Aggression_ALL, Aggression_ALL$Group == "Treatment") 

# EXPLORATION DATA
# Acclimation <- read.csv("../Data/Personality/Acclimation.csv")
Post_assay <- read.csv("../Data/Personality/Post-assay.csv")
```

### MAIN ANALYSIS 
1) CHECKING NORMALITY ASSUMPTIONS WITH MIXED MODELS AND A HISTOGRAM OF RESIDUALS
2) PERFORMING REPEATABILITY ANALYSIS FOR EACH GROUP AND EXTRACTING WITHIN-AND BETWEEN-INDIVIDUAL VARIANCES AFTER A Z TRANSFORMATION
3) CALCULATING DIFFERENCES BETWEEN REPEATABILITIES
4) FINAL MIXED MODEL USING LME FUNCTION
5) CALCULATING VARIANCE DIFFERENCES BETWEEN CONTROL AND TREATMENT

Exploration (Acclimation and post-stimulus); total distance traveled

```{r}


#Post assay

Model_post <- lmer(tot_dist_Activity ~ Group*Sex + (1 |Fish_ID), data = Post_assay) 
tab_model(Model_post)
hist(residuals(Model_post)) 

#Quick Visualization
Post_assay %>%
  ggplot(aes(Group, tot_dist_Activity, fill=Group)) +
  geom_violin(
    trim = FALSE,
    draw_quantiles = c(0.25, 0.5, 0.75), 
    alpha=0.5
  ) + 
  geom_point(position = "jitter", alpha = 0.7, size = 3)+
  facet_grid(~Sex)
```


Social Analysis - time spent near stimulus screen 
```{r}
#Check Normality with mixed model and then histogram of residuals

Model_Social_zone05 <- lmer(zone_05_dur ~ Group + Sex + (1 | Fish_ID), data = Social_ALL) 
tab_model(Model_Social_zone05)
hist(residuals(Model_Social_zone05)) 

Model_Social_zone052 <- lmer(zone_05_dur ~ Group*Sex + (1 | Fish_ID), data = Social_ALL) 
tab_model(Model_Social_zone052)
hist(residuals(Model_Social_zone052)) 

#Calculating repeatabilities using custom made functions
rpt_zone05(Social_Control) -> rpt_social_control
rpt_social_control
rpt_zone05(Social_Treatment) -> rpt_social_treatment
rpt_social_treatment

#Obtaining within-individual and between-individual variance 

rpt_within_zone05(Social_Control) -> within_between_social_control
within_between_social_control
rpt_within_zone05(Social_Treatment) -> within_between_social_treatment
within_between_social_treatment

#Obtaining differences between repeatabilities using custom made functions
Control_social_boot <- unlist_rptr(rpt_social_control)
Treatment_social_boot <- unlist_rptr(rpt_social_treatment) 
social_diff <- difference_boot(Treatment_social_boot,Control_social_boot)  
q_social <- quantiles_diff_boot(social_diff) #obtaining 95% CI
m_social <- mean(social_diff) #Obtaining mean
m_social
q_social

# Calculating difference in variance between control and treatment groups
Model_Social1 <- lme(zone_05_dur ~ Group*Sex-1, random = ~ 1| Fish_ID, data = Social_ALL, na.action=na.exclude) #mixed model without variance structure
summary(Model_Social1)
Model_Social2 <- lme(zone_05_dur ~ Group*Sex-1, random = ~ 1| Fish_ID, weights = varIdent(form=~1|Group), data = Social_ALL, na.action=na.exclude) #mixed model with variance structure varIdent
summary(Model_Social2)
anova(Model_Social1, Model_Social2) #calculating difference between two models to find difference in variance

#Quick Visualization
Social_ALL %>%
  ggplot(aes(Group, zone_05_dur, fill=Group)) +
  geom_violin(
    trim = FALSE,
    draw_quantiles = c(0.25, 0.5, 0.75), 
    alpha=0.5
  ) + 
  geom_point(position = "jitter", alpha = 0.7, size = 3)+
  facet_grid(~Sex)
```

Social Analysis - mean speed
```{r}
#Check Normality with mixed model and then histogram of residuals

Model_Social_speed <- lmer(mean_speed ~ Group + Sex + (1 | Fish_ID), data = Social_ALL) 
tab_model(Model_Social_speed)
hist(residuals(Model_Social_speed)) 


#Calculating repeatabilities using custom made functions
rpt_speed(Social_Control) -> rpt_social_control_speed
rpt_social_control_speed
rpt_speed(Social_Treatment) -> rpt_social_treatment_speed
rpt_social_treatment_speed

#Obtaining within-individual and between-individual variance 

rpt_within_speed(Social_Control) -> within_between_social_control_speed
within_between_social_control_speed
rpt_within_speed(Social_Treatment) -> within_between_social_treatment_speed
within_between_social_treatment_speed

#Obtaining differences between repeatabilities using custom made functions
Control_social_boot_speed <- unlist_rptr(rpt_social_control_speed)
Treatment_social_boot_speed <- unlist_rptr(rpt_social_treatment_speed) 
social_diff_speed <- difference_boot(Treatment_social_boot_speed,Control_social_boot_speed)  
q_social_speed <- quantiles_diff_boot(social_diff_speed) #obtaining 95% CI
m_social_speed <- mean(social_diff_speed) #Obtaining mean
m_social_speed
q_social_speed

# Calculating difference in variance between control and treatment groups
Model_Social1_speed <- lme(mean_speed ~ Group-1 + Sex, random = ~ 1| Fish_ID, data = Social_ALL, na.action=na.exclude) #mixed model without variance structure
summary(Model_Social1_speed)
Model_Social2_speed <- lme(mean_speed ~ Group-1 + Sex, random = ~ 1| Fish_ID, weights = varIdent(form=~1|Group), data = Social_ALL, na.action=na.exclude) #mixed model with variance structure varIdent
summary(Model_Social2_speed)
anova(Model_Social1_speed, Model_Social2_speed) #calculating difference between two models to find difference in variance

#Quick Visualization
Social_ALL %>%
  ggplot(aes(Group, mean_speed, fill=Group)) +
  geom_violin(
    trim = FALSE,
    draw_quantiles = c(0.25, 0.5, 0.75), 
    alpha=0.5
  ) + 
  geom_point(position = "jitter", alpha = 0.7, size = 3)
```

Social Analysis - total distance

```{r}
#Check Normality with mixed model and then histogram of residuals

Model_Social_tot_dist <- lmer(tot_dist ~ Group + Sex + (1 | Fish_ID), data = Social_ALL) 
tab_model(Model_Social_tot_dist)
hist(residuals(Model_Social_tot_dist)) 

Model_Social_tot_dist2 <- lmer(tot_dist ~ Group*Sex + (1 | Fish_ID), data = Social_ALL) 
tab_model(Model_Social_tot_dist2)
hist(residuals(Model_Social_tot_dist2)) 

#Calculating repeatabilities using custom made functions
rpt_tot_dist(Social_Control) -> rpt_social_control_dist
rpt_social_control_dist
rpt_tot_dist(Social_Treatment) -> rpt_social_treatment_dist
rpt_social_treatment_dist

#Obtaining within-individual and between-individual variance 

rpt_within_tot_dist(Social_Control) -> within_between_social_control_dist
within_between_social_control_dist
rpt_within_tot_dist(Social_Treatment) -> within_between_social_treatment_dist
within_between_social_treatment_dist

#Obtaining differences between repeatabilities using custom made functions
Control_social_boot_dist <- unlist_rptr(rpt_social_control_dist)
Treatment_social_boot_dist <- unlist_rptr(rpt_social_treatment_dist) 
social_diff_dist <- difference_boot(Treatment_social_boot,Control_social_boot)  
q_social_dist <- quantiles_diff_boot(social_diff_dist) #obtaining 95% CI
m_social_dist <- mean(social_diff_dist) #Obtaining mean
m_social_dist
q_social_dist

# Calculating difference in variance between control and treatment groups
Model_Social1_dist <- lme(tot_dist ~ Group*Sex-1, random = ~ 1| Fish_ID, data = Social_ALL, na.action=na.exclude) #mixed model without variance structure
summary(Model_Social1_dist)
Model_Social2_dist <- lme(tot_dist ~ Group*Sex-1, random = ~ 1| Fish_ID, weights = varIdent(form=~1|Group), data = Social_ALL, na.action=na.exclude) #mixed model with variance structure varIdent
summary(Model_Social2_dist)
anova(Model_Social1_dist, Model_Social2_dist) #calculating difference between two models to find difference in variance

#Quick Visualization
Social_ALL %>%
  ggplot(aes(Group, tot_dist, fill=Group)) +
  geom_violin(
    trim = FALSE,
    draw_quantiles = c(0.25, 0.5, 0.75), 
    alpha=0.5
  ) + 
  geom_point(position = "jitter", alpha = 0.7, size = 3)
```


Predator Analysis - time spent near stimulus screen 
```{r}
#Check Normality with mixed model and then histogram of residuals

Model_Predator_zone05 <- lmer(zone_05_dur ~ Group + Sex + (1 | Fish_ID), data = Predator_ALL) 
tab_model(Model_Predator_zone05)
hist(residuals(Model_Predator_zone05)) 


#Calculating repeatabilities using custom made functions
rpt_zone05(Predator_Control) -> rpt_predator_control
rpt_predator_control
rpt_zone05(Predator_Treatment) -> rpt_predator_treatment
rpt_predator_treatment

#Obtaining within-individual and between-individual variance 

rpt_within_zone05(Predator_Control) -> within_between_predator_control
within_between_predator_control
rpt_within_zone05(Predator_Treatment) -> within_between_predator_treatment
within_between_predator_treatment

#Obtaining differences between repeatabilities using custom made functions
Control_predator_boot <- unlist_rptr(rpt_predator_control)
Treatment_predator_boot <- unlist_rptr(rpt_predator_treatment) 
predator_diff <- difference_boot(Treatment_predator_boot,Control_predator_boot)  
q_predator <- quantiles_diff_boot(predator_diff) #obtaining 95% CI
m_predator <- mean(positive_diff) #Obtaining mean
m_predator
q_predator

# Calculating difference in variance between control and treatment groups
Model_Predator1 <- lme(zone_05_dur ~ Group-1 + Sex, random = ~ 1| Fish_ID, data = Predator_ALL, na.action=na.exclude) #mixed model without variance structure
summary(Model_Predator1)
Model_Predator2 <- lme(zone_05_dur ~ Group-1 + Sex, random = ~ 1| Fish_ID, weights = varIdent(form=~1|Group), data = Predator_ALL, na.action=na.exclude) #mixed model with variance structure varIdent
summary(Model_Predator2)
anova(Model_Predator1, Model_Predator2) #calculating difference between two models to find difference in variance

#Quick Visualization
Predator_ALL %>%
  ggplot(aes(Group, zone_05_dur, fill=Group)) +
  geom_violin(
    trim = FALSE,
    draw_quantiles = c(0.25, 0.5, 0.75), 
    alpha=0.5
  ) + 
  geom_point(position = "jitter", alpha = 0.7, size = 3)
```

Predator Analysis - mean speed
```{r}
#Check Normality with mixed model and then histogram of residuals

Model_Predator_speed <- lmer(mean_speed ~ Group + Sex + (1 | Fish_ID), data = Predator_ALL) 
tab_model(Model_Predator_speed)
hist(residuals(Model_Predator_speed)) 


#Calculating repeatabilities using custom made functions
rpt_speed(Predator_Control) -> rpt_predator_control_speed
rpt_predator_control_speed
rpt_speed(Predator_Treatment) -> rpt_predator_treatment_speed
rpt_predator_treatment_speed

#Obtaining within-individual and between-individual variance 

rpt_within_speed(Predator_Control) -> within_between_predator_control_speed
within_between_predator_control_speed
rpt_within_speed(Predator_Treatment) -> within_between_predator_treatment_speed
within_between_predator_treatment_speed

#Obtaining differences between repeatabilities using custom made functions
Control_predator_boot_speed <- unlist_rptr(rpt_predator_control_speed)
Treatment_predator_boot_speed <- unlist_rptr(rpt_predator_treatment_speed) 
predator_diff_speed <- difference_boot(Treatment_predator_boot_speed,Control_predator_boot_speed)  
q_predator_speed <- quantiles_diff_boot(predator_diff_speed) #obtaining 95% CI
m_predator_speed <- mean(predator_diff_speed) #Obtaining mean
m_predator_speed
q_predator_speed

# Calculating difference in variance between control and treatment groups
Model_Predator1_speed <- lme(mean_speed ~ Group-1 + Sex, random = ~ 1| Fish_ID, data = Predator_ALL, na.action=na.exclude) #mixed model without variance structure
summary(Model_Predator1_speed)
Model_Predator2_speed <- lme(mean_speed ~ Group-1 + Sex, random = ~ 1| Fish_ID, weights = varIdent(form=~1|Group), data = Predator_ALL, na.action=na.exclude) #mixed model with variance structure varIdent
summary(Model_Predator2_speed)
anova(Model_Predator1_speed, Model_Predator2_speed) #calculating difference between two models to find difference in variance

#Quick Visualization
Predator_ALL %>%
  ggplot(aes(Group, mean_speed, fill=Group)) +
  geom_violin(
    trim = FALSE,
    draw_quantiles = c(0.25, 0.5, 0.75), 
    alpha=0.5
  ) + 
  geom_point(position = "jitter", alpha = 0.7, size = 3)
```

Predator Analysis - total distance

```{r}
#Check Normality with mixed model and then histogram of residuals

Model_Predator_tot_dist <- lmer(tot_dist ~ Group + Sex + (1 | Fish_ID), data = Predator_ALL) 
tab_model(Model_Predator_tot_dist)
hist(residuals(Model_Predator_tot_dist)) 

Model_Predator_tot_dist2 <- lmer(tot_dist ~ Group*Sex + (1 | Fish_ID), data = Predator_ALL) 
tab_model(Model_Predator_tot_dist2)
hist(residuals(Model_Predator_tot_dist2)) 

#Calculating repeatabilities using custom made functions
rpt_tot_dist(Predator_Control) -> rpt_predator_control_dist
rpt_predator_control_dist
rpt_tot_dist(Predator_Treatment) -> rpt_predator_treatment_dist
rpt_predator_treatment_dist

#Obtaining within-individual and between-individual variance 

rpt_within_tot_dist(Predator_Control) -> within_between_predator_control_dist
within_between_predator_control_dist
rpt_within_tot_dist(Predator_Treatment) -> within_between_predator_treatment_dist
within_between_predator_treatment_dist

#Obtaining differences between repeatabilities using custom made functions
Control_predator_boot_dist <- unlist_rptr(rpt_predator_control_dist)
Treatment_predator_boot_dist <- unlist_rptr(rpt_predator_treatment_dist) 
predator_diff_dist <- difference_boot(Treatment_predator_boot,Control_predator_boot)  
q_predator_dist <- quantiles_diff_boot(predator_diff_dist) #obtaining 95% CI
m_predator_dist <- mean(predator_diff_dist) #Obtaining mean
m_predator_dist
q_predator_dist

# Calculating difference in variance between control and treatment groups
Model_Predator1_dist <- lme(tot_dist ~ Group*Sex-1, random = ~ 1| Fish_ID, data = Predator_ALL, na.action=na.exclude) #mixed model without variance structure
summary(Model_Predator1_dist)
Model_Predator2_dist <- lme(tot_dist ~ Group*Sex-1, random = ~ 1| Fish_ID, weights = varIdent(form=~1|Group), data = Predator_ALL, na.action=na.exclude) #mixed model with variance structure varIdent
summary(Model_Predator2_dist)
anova(Model_Predator1_dist, Model_Predator2_dist) #calculating difference between two models to find difference in variance

#Quick Visualization
Predator_ALL %>%
  ggplot(aes(Group, tot_dist, fill=Group)) +
  geom_violin(
    trim = FALSE,
    draw_quantiles = c(0.25, 0.5, 0.75), 
    alpha=0.5
  ) + 
  geom_point(position = "jitter", alpha = 0.7, size = 3)
```


Novel Analysis - time spent near stimulus screen 
```{r}
#Check Normality with mixed model and then histogram of residuals

Model_Novel_zone05 <- lmer(zone_05_dur ~ Group + Sex + (1 | Fish_ID), data = Novel_ALL) 
tab_model(Model_Novel_zone05)
hist(residuals(Model_Novel_zone05)) #data skewed, needs transformation

Model_Novel_zone052 <- lmer(sqrt(zone_05_dur) ~ Group + Sex + (1 | Fish_ID), data = Novel_ALL) 
tab_model(Model_Novel_zone052)
hist(residuals(Model_Novel_zone052))


#Calculating repeatabilities using custom made functions
rpt_zone05(Novel_Control) -> rpt_novel_control
rpt_novel_control
rpt_zone05(Novel_Treatment) -> rpt_novel_treatment
rpt_novel_treatment

#Obtaining within-individual and between-individual variance 

rpt_within_zone05(Novel_Control) -> within_between_novel_control
within_between_novel_control
rpt_within_zone05(Novel_Treatment) -> within_between_novel_treatment
within_between_novel_treatment

#Obtaining differences between repeatabilities using custom made functions
Control_novel_boot <- unlist_rptr(rpt_novel_control)
Treatment_novel_boot <- unlist_rptr(rpt_novel_treatment) 
novel_diff <- difference_boot(Control_novel_boot,Treatment_novel_boot)  
q_novel <- quantiles_diff_boot(novel_diff) #obtaining 95% CI
m_novel <- mean(novel_diff) #Obtaining mean
m_novel
q_novel

# Calculating difference in variance between control and treatment groups
Model_Novel1 <- lme(sqrt(zone_05_dur) ~ Group-1 + Sex, random = ~ 1| Fish_ID, data = Novel_ALL, na.action=na.exclude) #mixed model without variance structure
summary(Model_Novel1)
Model_Novel2 <- lme(sqrt(zone_05_dur) ~ Group-1 + Sex, random = ~ 1| Fish_ID, weights = varIdent(form=~1|Group), data = Novel_ALL, na.action=na.exclude) #mixed model with variance structure varIdent
summary(Model_Novel2)
anova(Model_Novel1, Model_Novel2) #calculating difference between two models to find difference in variance

#Quick Visualization
Novel_ALL %>%
  ggplot(aes(Group, zone_05_dur, fill=Group)) +
  geom_violin(
    trim = FALSE,
    draw_quantiles = c(0.25, 0.5, 0.75), 
    alpha=0.5
  ) + 
  geom_point(position = "jitter", alpha = 0.7, size = 3)
```

Novel Analysis - mean speed
```{r}
#Check Normality with mixed model and then histogram of residuals

Model_Novel_speed <- lmer(mean_speed ~ Group + Sex + (1 | Fish_ID), data = Novel_ALL) 
tab_model(Model_Novel_speed)
hist(residuals(Model_Novel_speed)) 


#Calculating repeatabilities using custom made functions
rpt_speed(Novel_Control) -> rpt_novel_control_speed
rpt_novel_control_speed
rpt_speed(Novel_Treatment) -> rpt_novel_treatment_speed
rpt_novel_treatment_speed

#Obtaining within-individual and between-individual variance 

rpt_within_speed(Novel_Control) -> within_between_novel_control_speed
within_between_novel_control_speed
rpt_within_speed(Novel_Treatment) -> within_between_novel_treatment_speed
within_between_novel_treatment_speed

#Obtaining differences between repeatabilities using custom made functions
Control_novel_boot_speed <- unlist_rptr(rpt_novel_control_speed)
Treatment_novel_boot_speed <- unlist_rptr(rpt_novel_treatment_speed) 
novel_diff_speed <- difference_boot(Control_novel_boot_speed,Treatment_novel_boot_speed)  
q_novel_speed <- quantiles_diff_boot(novel_diff_speed) #obtaining 95% CI
m_novel_speed <- mean(novel_diff_speed) #Obtaining mean
m_novel_speed
q_novel_speed

# Calculating difference in variance between control and treatment groups
Model_Novel1_speed <- lme(mean_speed ~ Group-1 + Sex, random = ~ 1| Fish_ID, data = Novel_ALL, na.action=na.exclude) #mixed model without variance structure
summary(Model_Novel1_speed)
Model_Novel2_speed <- lme(mean_speed ~ Group-1 + Sex, random = ~ 1| Fish_ID, weights = varIdent(form=~1|Group), data = Novel_ALL, na.action=na.exclude) #mixed model with variance structure varIdent
summary(Model_Novel2_speed)
anova(Model_Novel1_speed, Model_Novel2_speed) #calculating difference between two models to find difference in variance

#Quick Visualization
Novel_ALL %>%
  ggplot(aes(Group, mean_speed, fill=Group)) +
  geom_violin(
    trim = FALSE,
    draw_quantiles = c(0.25, 0.5, 0.75), 
    alpha=0.5
  ) + 
  geom_point(position = "jitter", alpha = 0.7, size = 3)
```

Novel Analysis - total distance

```{r}
#Check Normality with mixed model and then histogram of residuals

Model_Novel_tot_dist <- lmer(tot_dist ~ Group + Sex + (1 | Fish_ID), data = Novel_ALL) 
tab_model(Model_Novel_tot_dist)
hist(residuals(Model_Novel_tot_dist)) 

Model_Novel_tot_dist2 <- lmer(tot_dist ~ Group*Sex + (1 | Fish_ID), data = Novel_ALL) 
tab_model(Model_Novel_tot_dist2)
hist(residuals(Model_Novel_tot_dist2)) 

#Calculating repeatabilities using custom made functions
rpt_tot_dist(Novel_Control) -> rpt_novel_control_dist
rpt_novel_control_dist
rpt_tot_dist(Novel_Treatment) -> rpt_novel_treatment_dist
rpt_novel_treatment_dist

#Obtaining within-individual and between-individual variance 

rpt_within_tot_dist(Novel_Control) -> within_between_novel_control_dist
within_between_novel_control_dist
rpt_within_tot_dist(Novel_Treatment) -> within_between_novel_treatment_dist
within_between_novel_treatment_dist

#Obtaining differences between repeatabilities using custom made functions
Control_novel_boot_dist <- unlist_rptr(rpt_novel_control_dist)
Treatment_novel_boot_dist <- unlist_rptr(rpt_novel_treatment_dist) 
novel_diff_dist <- difference_boot(Treatment_novel_boot,Control_novel_boot)  
q_novel_dist <- quantiles_diff_boot(novel_diff_dist) #obtaining 95% CI
m_novel_dist <- mean(novel_diff_dist) #Obtaining mean
m_novel_dist
q_novel_dist

# Calculating difference in variance between control and treatment groups
Model_Novel1_dist <- lme(tot_dist ~ Group*Sex-1, random = ~ 1| Fish_ID, data = Novel_ALL, na.action=na.exclude) #mixed model without variance structure
summary(Model_Novel1_dist)
Model_Novel2_dist <- lme(tot_dist ~ Group*Sex-1, random = ~ 1| Fish_ID, weights = varIdent(form=~1|Group), data = Novel_ALL, na.action=na.exclude) #mixed model with variance structure varIdent
summary(Model_Novel2_dist)
anova(Model_Novel1_dist, Model_Novel2_dist) #calculating difference between two models to find difference in variance

#Quick Visualization
Novel_ALL %>%
  ggplot(aes(Group, tot_dist, fill=Group)) +
  geom_violin(
    trim = FALSE,
    draw_quantiles = c(0.25, 0.5, 0.75), 
    alpha=0.5
  ) + 
  geom_point(position = "jitter", alpha = 0.7, size = 3)
```

Aggression Analysis - time spent near stimulus screen 
```{r}
#Check Normality with mixed model and then histogram of residuals

Model_Aggression_zone05 <- lmer(zone_05_dur ~ Group + Sex + (1 | Fish_ID), data = Aggression_ALL) 
tab_model(Model_Aggression_zone05)
hist(residuals(Model_Aggression_zone05)) 


#Calculating repeatabilities using custom made functions
rpt_zone05(Aggression_Control) -> rpt_aggression_control
rpt_aggression_control
rpt_zone05(Aggression_Treatment) -> rpt_aggression_treatment
rpt_aggression_treatment

#Obtaining within-individual and between-individual variance 

rpt_within_zone05(Aggression_Control) -> within_between_aggression_control
within_between_aggression_control
rpt_within_zone05(Aggression_Treatment) -> within_between_aggression_treatment
within_between_aggression_treatment

#Obtaining differences between repeatabilities using custom made functions
Control_aggression_boot <- unlist_rptr(rpt_aggression_control)
Treatment_aggression_boot <- unlist_rptr(rpt_aggression_treatment) 
aggression_diff <- difference_boot(Treatment_aggression_boot,Control_aggression_boot)  
q_aggression <- quantiles_diff_boot(aggression_diff) #obtaining 95% CI
m_aggression <- mean(aggression_diff) #Obtaining mean
m_aggression
q_aggression

# Calculating difference in variance between control and treatment groups
Model_Aggression1 <- lme(zone_05_dur ~ Group-1 + Sex, random = ~ 1| Fish_ID, data = Aggression_ALL, na.action=na.exclude) #mixed model without variance structure
summary(Model_Aggression1)
Model_Aggression2 <- lme(zone_05_dur ~ Group-1 + Sex, random = ~ 1| Fish_ID, weights = varIdent(form=~1|Group), data = Aggression_ALL, na.action=na.exclude) #mixed model with variance structure varIdent
summary(Model_Aggression2)
anova(Model_Aggression1, Model_Aggression2) #calculating difference between two models to find difference in variance

#Quick Visualization
Aggression_ALL %>%
  ggplot(aes(Group, zone_05_dur, fill=Group)) +
  geom_violin(
    trim = FALSE,
    draw_quantiles = c(0.25, 0.5, 0.75), 
    alpha=0.5
  ) + 
  geom_point(position = "jitter", alpha = 0.7, size = 3)
```

Aggression Analysis - mean speed
```{r}
#Check Normality with mixed model and then histogram of residuals

Model_Aggression_speed <- lmer(mean_speed ~ Group + Sex + (1 | Fish_ID), data = Aggression_ALL) 
tab_model(Model_Aggression_speed)
hist(residuals(Model_Aggression_speed)) 


#Calculating repeatabilities using custom made functions
rpt_speed(Aggression_Control) -> rpt_aggression_control_speed
rpt_aggression_control_speed
rpt_speed(Aggression_Treatment) -> rpt_aggression_treatment_speed
rpt_aggression_treatment_speed

#Obtaining within-individual and between-individual variance 

rpt_within_speed(Aggression_Control) -> within_between_aggression_control_speed
within_between_aggression_control_speed
rpt_within_speed(Aggression_Treatment) -> within_between_aggression_treatment_speed
within_between_aggression_treatment_speed

#Obtaining differences between repeatabilities using custom made functions
Control_aggression_boot_speed <- unlist_rptr(rpt_aggression_control_speed)
Treatment_aggression_boot_speed <- unlist_rptr(rpt_aggression_treatment_speed) 
aggression_diff_speed <- difference_boot(Control_aggression_boot_speed,Treatment_aggression_boot_speed)  
q_aggression_speed <- quantiles_diff_boot(aggression_diff_speed) #obtaining 95% CI
m_aggression_speed <- mean(aggression_diff_speed) #Obtaining mean
m_aggression_speed
q_aggression_speed

# Calculating difference in variance between control and treatment groups
Model_Aggression1_speed <- lme(mean_speed ~ Group-1 + Sex, random = ~ 1| Fish_ID, data = Aggression_ALL, na.action=na.exclude) #mixed model without variance structure
summary(Model_Aggression1_speed)
Model_Aggression2_speed <- lme(mean_speed ~ Group-1 + Sex, random = ~ 1| Fish_ID, weights = varIdent(form=~1|Group), data = Aggression_ALL, na.action=na.exclude) #mixed model with variance structure varIdent
summary(Model_Aggression2_speed)
anova(Model_Aggression1_speed, Model_Aggression2_speed) #calculating difference between two models to find difference in variance

#Quick Visualization
Aggression_ALL %>%
  ggplot(aes(Group, mean_speed, fill=Group)) +
  geom_violin(
    trim = FALSE,
    draw_quantiles = c(0.25, 0.5, 0.75), 
    alpha=0.5
  ) + 
  geom_point(position = "jitter", alpha = 0.7, size = 3)
```

Aggression Analysis - total distance

```{r}
#Check Normality with mixed model and then histogram of residuals

Model_Aggression_tot_dist <- lmer(tot_dist ~ Group + Sex + (1 | Fish_ID), data = Aggression_ALL) 
tab_model(Model_Aggression_tot_dist)
hist(residuals(Model_Aggression_tot_dist)) 

Model_Aggression_tot_dist2 <- lmer(tot_dist ~ Group*Sex + (1 | Fish_ID), data = Aggression_ALL) 
tab_model(Model_Aggression_tot_dist2)
hist(residuals(Model_Aggression_tot_dist2)) 

#Calculating repeatabilities using custom made functions
rpt_tot_dist(Aggression_Control) -> rpt_aggression_control_dist
rpt_aggression_control_dist
rpt_tot_dist(Aggression_Treatment) -> rpt_aggression_treatment_dist
rpt_aggression_treatment_dist

#Obtaining within-individual and between-individual variance 

rpt_within_tot_dist(Aggression_Control) -> within_between_aggression_control_dist
within_between_aggression_control_dist
rpt_within_tot_dist(Aggression_Treatment) -> within_between_aggression_treatment_dist
within_between_aggression_treatment_dist

#Obtaining differences between repeatabilities using custom made functions
Control_aggression_boot_dist <- unlist_rptr(rpt_aggression_control_dist)
Treatment_aggression_boot_dist <- unlist_rptr(rpt_aggression_treatment_dist) 
aggression_diff_dist <- difference_boot(Treatment_aggression_boot,Control_aggression_boot)  
q_aggression_dist <- quantiles_diff_boot(aggression_diff_dist) #obtaining 95% CI
m_aggression_dist <- mean(aggression_diff_dist) #Obtaining mean
m_aggression_dist
q_aggression_dist

# Calculating difference in variance between control and treatment groups
Model_Aggression1_dist <- lme(tot_dist ~ Group*Sex-1, random = ~ 1| Fish_ID, data = Aggression_ALL, na.action=na.exclude) #mixed model without variance structure
summary(Model_Aggression1_dist)
Model_Aggression2_dist <- lme(tot_dist ~ Group*Sex-1, random = ~ 1| Fish_ID, weights = varIdent(form=~1|Group), data = Aggression_ALL, na.action=na.exclude) #mixed model with variance structure varIdent
summary(Model_Aggression2_dist)
anova(Model_Aggression1_dist, Model_Aggression2_dist) #calculating difference between two models to find difference in variance

#Quick Visualization
Aggression_ALL %>%
  ggplot(aes(Group, tot_dist, fill=Group)) +
  geom_violin(
    trim = FALSE,
    draw_quantiles = c(0.25, 0.5, 0.75), 
    alpha=0.5
  ) + 
  geom_point(position = "jitter", alpha = 0.7, size = 3)
```

## ROSE: looking at residuals
```{r}
# load("~/Dropbox/Shinichi/Postdoc/F0_Chapter_Analysis/Scripts/myEnvironment.RData")
hist(residuals(Model_acclimation))                                    
hist(residuals(Model_post))                                           
hist(residuals(Model_Social_zone05))  # negatively skewed                                 
hist(residuals(Model_Social_zone052)) # negatively skewed                                   
hist(residuals(Model_Social_speed))   # positively skewed                                
hist(residuals(Model_Social_tot_dist))# positively skewed                                 
hist(residuals(Model_Social_tot_dist2))# positively skewed                               
hist(residuals(Model_Predator_zone05))# positively skewed                                
hist(residuals(Model_Predator_speed))                                 
hist(residuals(Model_Predator_tot_dist))                              
hist(residuals(Model_Predator_tot_dist2))                             
hist(residuals(Model_Novel_zone05)) # positively skewed
hist(residuals(Model_Novel_zone052)) # tails too fat                                  
hist(residuals(Model_Novel_speed)) # tails too skinny                                   
hist(residuals(Model_Novel_tot_dist)) # negatively skewed                                 
hist(residuals(Model_Novel_tot_dist2)) # negatively skewed                                
hist(residuals(Model_Aggression_zone05))                              
hist(residuals(Model_Aggression_speed)) # tails too thin                             
hist(residuals(Model_Aggression_tot_dist)) # tails too thin                             
hist(residuals(Model_Aggression_tot_dist2))  # tails too thin  
```

### ROSE: converting from wide to long data format   
```{r}
Personality <- read.csv("../Data/Personality/ALL.csv")

# making a column with a factor where the four levels correspond to the four phases
Personality$phase <-  factor(Personality$Time, levels = c("6-9", "13-16", "20-23", "27-30")) 

# making a list where each level of the list is a different phase
phases <- split(Personality, Personality$phase)

# function to apply to the four phases: 1, 2, 3, and 4
func_phase <- function(phase = 1){
    df <- phases[[phase]] # getting phase dataframe based on index (1-4)
    df$Behaviour <- df[,paste0("Phase",phase)] # getting columns that says which behaviour was in that phase
    df <- df[,!(names(df) %in% paste0("Phase", 1:4))] # removing the now-redundant Phase1,...,Phase4 columns
    return(df) # return dataframe
}

# applying function, returning a list of four dataframes
Personality_list <- lapply(1:4, function(x) func_phase(x))
Personality_df <- bind_rows(Personality_list) # stakes dataframe on top of each other

# making an ID for the tank info (four phases in a session)
Personality_df <- Personality_df %>% mutate(fish_session_ID = paste(Fish_ID, Date, Session, Camera, Tank)) %>% arrange(fish_session_ID) # ROSE2: since the 'ALL.csv' data file has been updated, 'Tank' column is missing, so this needs to change
Personality_df <- Personality_df %>% mutate(fish_session_ID = paste(Fish_ID, Date, Session, Camera)) %>% arrange(fish_session_ID) # ROSE2: correction since data update

# turning from wide to long
vars <- c("tot_dist", "mean_speed", "mean_dist_05",  
          "tot_dist_05", "freeze_dur", "zone_510_dur",  
          "zone_05_dur",  "zone_2025_dur","zone_1520_dur", 
          "zone_3035_dur", "zone_1015_dur", "zone_3540_dur", 
          "zone_2530_dur", "zone_near_dur", "zone_middle_dur", 
          "zone_far_dur",  "arena_dur",  "moving_dur")
info <- c("Time", "Day", "Date", "Video",   "Arena",   "Sex", "Mark", "Session", "Camera",  "Tank", "Group",  "Fish_ID", "Notes") # ROSE2: again, not working after data update
info[!(info %in% names(Personality_df))] # Tank and Video missing
info <- c("Time", "Day", "Date",  "Arena",   "Sex", "Mark", "Session", "Camera",  "Group",  "Fish_ID", "Notes")#ROSE2: removing missing tank and video

# four behaviours
behavs <- c("Aggression", "Novel", "Predator", "Social")

# function to rename variables for each behaviour
func_variable_behav <- function(behav = behavs[1]){
    behav_vars <- Personality_df[Personality_df$Behaviour == behav,vars] # getting just the variables for that behaviour
    names(behav_vars) <- paste(names(behav_vars), behav, sep = "_") # renaming variables so they say which behaviour they relate to
    return(behav_vars)
}
# applying function to each behaviour
vars_behavs_list <- lapply(behavs, function(x) func_variable_behav(x))
# putting the four behaviour columns next to each other
vars_behavs <- bind_cols(vars_behavs_list) 

# adding info
Personality_wide <- cbind(Personality_df[Personality_df$Behaviour == "Aggression", info], vars_behavs)
```

### Adding in activity data (post-assay) to Personality_wide
```{r}
Personality_wide <- left_join(Post_assay, Personality_wide)
# 
# # Was a simple task considering the post-assay period was just one set period in all videos. Left join was all that was required to join by the same variables. The joining was successful considering that the number of observations did not change, however the number of variables increased. Cleaning up the original excel file also meant joining was easy. 
# 
# names(Personality_wide)[names(Personality_wide)=="Phase"] <- "Phase5"
# # dplyr wasn't working so had to use base functions for now to just incorporate activity as "Phase5"# ROSE2: not sure what is meant by this?

# five behaviours
behavs <- c("Aggression", "Novel", "Predator", "Social", "Activity") #modified to include activity so we can run functions below

#Data was double checked by Rose
```


### ROSE: residual distributions and repeatability values for each variable    
Using Shapiro-Wilk normality test   
See ?shapiro.test
More normal = higher W value and smaller p value
```{r}
func_behav_raw <- function(behav = behavs[1]){
  
  func_var <- function(var = vars[1]){
    mod <- lmer(Personality_wide[,paste(var,behav,sep="_")] ~ Group*Sex + (1 | Fish_ID), data = Personality_wide) 
    residuals <- resid(mod)
    VC <- data.frame(VarCorr(mod))
    rpt <- round(VC$vcov[1]/sum(VC$vcov),2)
    sw <- shapiro.test(residuals)
    df <- data.frame(behav, var, rpt, W = round(sw$statistic,3), p = round(sw$p.value,3))
    return(df)
  } # raw general linear model to determine whether transformations are required
  

  
 rpt_vals <- bind_rows(lapply(vars, function(x) func_var(x)))
 return(rpt_vals)
}

func_behav_sqrt <- function(behav = behavs[1]){
  
  func_var <- function(var = vars[1]){
    mod <- lmer(sqrt(Personality_wide[,paste(var,behav,sep="_")]) ~ Group*Sex + (1 | Fish_ID), data = Personality_wide) # added a square root transformation here to the model
    residuals <- resid(mod)
    VC <- data.frame(VarCorr(mod))
    rpt <- round(VC$vcov[1]/sum(VC$vcov),2)
    sw <- shapiro.test(residuals)
    df <- data.frame(behav, var, rpt, W = round(sw$statistic,3), p = round(sw$p.value,3))
    return(df)
  } # same general linear model as above but with a square root transformation
  

  
 rpt_vals <- bind_rows(lapply(vars, function(x) func_var(x)))
 return(rpt_vals)
}

# RUNNING MODELS 

rpt_resids <- bind_rows(lapply(behavs, function(x) func_behav_raw(x))) # not transformed

rpt_resids_sqrt <- bind_rows(lapply(behavs, function(x) func_behav_sqrt(x))) # sqrt transformed

# CHECKING TO SEE WHICH VARIABLES ARE NORMAL AND WHICH REQUIRE TRANSFORMATION

# restricting to just values of W > 0.9 and seeing which variables are represented for all behaviors

rpt_resids %>% filter(W>0.9) %>% group_by(var) %>% tally()


# only mean_speed and tot_dist are there for everything


filter(rpt_resids, var == "mean_speed") # all looks good, except p-val for Aggression?

filter(rpt_resids, var == "tot_dist") # similar to above?

# zone_near_dur there for 4/5, so we want to check which phase would need to be transformed 

filter(rpt_resids, var == "zone_near_dur") 

#this shows that the "Social" phase needs a transformation for the variable zone_near_dur, so we'll see if a square root transformation helps

rpt_resids_sqrt %>% filter(W>0.9) %>% group_by(var) %>% tally()

filter(rpt_resids_sqrt, var == "zone_near_dur")

# The square root transformation doesn't help for the variable zone_near_dur for the Social phase, so will try to identify another variable that can be used for all 5 phases as long as transformations work

rpt_resids %>% filter(W>0.9) %>% group_by(var) %>% tally()

#Will try to see tot_dist_05
 
filter(rpt_resids, var == "tot_dist_05")

#Social and Aggression require transformations, will see if the sqrt transformations helped

filter(rpt_resids_sqrt, var == "tot_dist_05")

#Aggression phase is good with a square root transformation, Social phase improved, possibility it can be used?

# Will now check zone_05_dur

filter(rpt_resids, var == "zone_05_dur")

#Not too fussed with Activity phase as we will use a distance variable, however, Novel phase needs to be transformed. Will see if the transformation helps with normality

filter(rpt_resids_sqrt, var == "zone_05_dur")

#A square root transformation appears to have done the job.

# To summarize, we can use the following variables for analysis

# Mean speed (all 5 phases), total distance (all 5 phases), zone_05_dur (Novel phases requires a square root transformation)





```


### Run lmer models for chosen behaviour   
```{r}
#ROSE2: To-do:
# - Write a function that will input your variable name and output the model
# - use lapply to apply that function across all behaviors
# - add more notes/annotation justifying your chosen variables

#Variables of choice due to normality analysis

# Mean speed (all 5 phases), total distance (all 5 phases), zone_05_dur (Novel phases requires a square root transformation)

#Variables are also biologically relevant, in particular time spent near the stimulus screen (zone_05_dur)

# First we require our function for mixed models
func_mod <- function(var,squareroot = F, df = Personality_wide){
  mod <- lmer(df[,var] ~ Group*Sex + (1 | Fish_ID), data = df)
  if(squareroot == TRUE){
    mod <- lmer(sqrt(df[,var]) ~ Group*Sex + (1 | Fish_ID), data = df) #Note how we added a square root transformation if needed
  }

  return(mod) #Must return the model and not the summary of the model
  
}

func_mod(Personality_wide$tot_dist_Novel)

#Total distance

tot_dist <- c("tot_dist_Novel", "tot_dist_Social", "tot_dist_Predator", "tot_dist_Activity", "tot_dist_Aggression") #creating a vector to use when we apply models to all behaviors

mod_list <- lapply(tot_dist, function(x) func_mod(x)) #using lapply to apply function to all behaviors

names(mod_list) <- tot_dist # Assigning names to the models, am not sure if I could've done this earlier but will ensure I named the elements of the list correctly

tot_dist_Novel_check <- lmer(tot_dist_Novel ~ Group*Sex + (1 | Fish_ID), data = Personality_wide)
tab_model(tot_dist_Novel_check) #See tab that appears on right side and now compare to your lapply version

mod_list$tot_dist_Novel #Summaries match

tot_dist_Social_check <- lmer(tot_dist_Social ~ Group*Sex + (1 | Fish_ID), data = Personality_wide)
tab_model(tot_dist_Social_check) #See tab that appears on right side and now compare to the lapply version

mod_list$tot_dist_Social #Summaries match

hist(residuals(tot_dist_Social_check)) #Checking to see if residuals match

hist(residuals(mod_list$tot_dist_Social)) #Residuals matching

#From these summaries, am confident the rest of the model summaries are matching as it is following the order of the vector

#Mean speed

mean_speed <- c("mean_speed_Novel", "mean_speed_Social", "mean_speed_Predator", "mean_speed_Activity", "mean_speed_Aggression") #creating a vector to use when we apply models to all behaviors

mod_list_speed <- lapply(mean_speed, function(x) func_mod(x))

names(mod_list_speed) <- mean_speed

mod_list_speed

#Zone 05 duration (time spent near stimulus screen)

zone_05 <- c("zone_05_dur_Social", "zone_05_dur_Predator", "zone_05_dur_Activity", "zone_05_dur_Aggression") #not including novel behavior as this requires a transformation, however we can go ahead and use lapply to apply our function to the other 4 behaviors

mod_list_zone05 <- lapply(zone_05, function(x) func_mod(x)) 

names(mod_list_zone05) <- zone_05



#Don't need lapply for one behavior, so can go ahead and use the function

lmer_zone_05_dur_Novel <- func_mod("zone_05_dur_Novel", squareroot = TRUE)
hist(residuals(lmer_zone_05_dur_Novel)) #Residuals appear better



```


### Extract BLUPs from lmer models and plot fitted versus. predicted      
- make a dataframe with the model parameters    
- fitted = the actual measured behaviors
- predicted = the model predictions, calculated according to the below equation:

$$y_{ij} = \beta_0 + \text{ID}_j + \beta_1(\text{treatment})+ \beta_2(\text{male}) + \beta_3(\text{treatment}\cdot\text{male})$$ 


```{r}
#ROSE2: To-do:
# - Write a function that will input your model name and output your dataframe of fitted and predicted values   
# - use lapply to apply that function across all your models  

#HAMZA2: Having trouble with the lapply because I can't figure out how to use gsub properly :/

# example:
mod = lmer_zone_05_dur_Aggression #For the gsubbing, we just need any example

mod_name = "lmer_zone_05_dur_Aggression"
mod = get(mod_name)

gsub("lmer\\_", "", mod_name) -> var_name


# getting population parameters
betas <- fixef(mod)
b0 <- betas[1]
b1 <- betas[2]
b2 <- betas[3]
b3 <- betas[4]

# getting blups
blups <- data.frame(ranef(mod))
round(mean(blups$condval)) # average of blups = 0

# finding the treatment and male value for each fish_ID
fish_ID <- as.character(blups$grp)
# need to match fish_ID ID with their info
pos <- match(fish_ID, Personality_wide$Fish_ID)
(Personality_wide$Fish_ID[pos] == fish_ID) # all TRUE

# making dataframe of parameters
mod_pars <- data.frame(fish_ID, b0, ID = blups$condval, b1, b2, b3, treatment = ifelse(Personality_wide$Group[pos] == "Treatment",1,0), male = ifelse(Personality_wide$Sex[pos]=="male",1,0)) %>% mutate(predicted = b0 + ID + b1*treatment + b2*male + b3*(treatment*male))
# finding predicted values
pos <- match(Personality_wide$Fish_ID, mod_pars$fish_ID)
(mod_pars$fish_ID[pos]==Personality_wide$Fish_ID) # all TRUE
fitted_predicted <- mod_pars[pos,] %>% mutate(fitted = Personality_wide$zone_05_dur_Aggression)
plot(fitted_predicted$fitted, fitted_predicted$predicted)
cor(fitted_predicted$fitted, fitted_predicted$predicted)^2 # R2 value


func_fitted_predicted <- function(mod,variable){ #I have so far just put the top code into the function :/
  betas <- fixef(mod)
  b0 <- betas[1]
b1 <- betas[2]
b2 <- betas[3]
b3 <- betas[4]
# getting blups
blups <- data.frame(ranef(mod))
round(mean(blups$condval)) # average of blups = 0
# finding the treatment and male value for each fish_ID
fish_ID <- as.character(blups$grp)
# need to match fish_ID ID with their info
pos <- match(fish_ID, Personality_wide$Fish_ID)
(Personality_wide$Fish_ID[pos] == fish_ID) # all TRUE
# finding predicted values
pos <- match(Personality_wide$Fish_ID, mod_pars$fish_ID)
(mod_pars$fish_ID[pos]==Personality_wide$Fish_ID) # all TRUE
fitted_predicted <- mod_pars[pos,] %>% mutate(fitted = variable)#This is where I'm having trouble, because it has to be unique and I'm not sure how to use gsub here :/
lt = list=c(plot(fitted_predicted$fitted, fitted_predicted$predicted),cor(fitted_predicted$fitted, fitted_predicted$predicted)^2)
return(lt) #return both the R2 value as well as the plot of fitted vs residuals

}

func_fitted_predicted(mod_list$tot_dist_Social, Personality_wide$tot_dist_Social) 

#function appears to be working as I am using a different variable and I'm getting an R2 value as well as the plot of fitted vs residuals,however this won't work with lapply because I'm relying on inputting the specific model and specific variable from the datasheet :/ Need to use gsub or vars_behavs but can't quite figure it out :(

mod_list_all <- c(mod_list, mod_list_speed, mod_list_zone05, mod_list_zone05_sqrt) #Am sure this is the way to create the list to use in lapply

fit_predict_list <- lapply(mod_list_all, function(x) func_fitted_predicted(x)) #How I would use lapply once I figure out my issue
```


### Repeat the above steps in brm (which uses stan), and compare the results to the lmer models   
```{r}
#ROSE2: To-do:
# - Write a function that will input your variable name, run, and save your brm model 
# - use lapply to apply that function across all your variable names
# - save one Rdata file with all your brm models   
# - Write a function that will input your brm model object, and output two things: (1) the posterior distributions of population paramaters; (2) the fitted and predicted values for posterior means.


library(brms)
#options(mc.scores = parallel::detectCores()) # allows chains to run simultaneously, but needs enough RAM
# brm_zone_05_dur_Aggression <- brm(formula = zone_05_dur_Aggression ~ Group*Sex + (1 | Fish_ID), 
#                                   data = Personality_wide,
#                                   family = gaussian(),
#                                   chains = 3,
#                                   iter = 2000, # iter and warmup quite short, as this is just a practice
#                                   warmup = 1000)  
save(brm_zone_05_dur_Aggression, file = "../Models/brm_zone_05_dur_Aggression.Rdata")

load("../Models/brm_zone_05_dur_Aggression.Rdata")
mod_posterior <- as.data.frame(brm_zone_05_dur_Aggression)
post_means <- apply(mod_posterior, 2, function(x) round(mean(x),4))

#Function to do the above

func_brm_mod <- function(var, df = Personality_wide){
  brm <- brm(formula = df[,var] ~ Group*Sex + (1 | Fish_ID), 
                                  data = df,
                                  family = gaussian(),
                                  chains = 3,
                                 iter = 2000, warmup = 1000)  

  return(brm)
}

#Testing function
func_brm_mod("zone_05_dur_Aggression") #Function doesn't appear to be working, am not sure why :/

#Using lapply to use function for all behaviors for total distance

mod_list <- lapply(tot_dist, function(x) func_brm_mod(x))


#Another example

options(mc.scores = parallel::detectCores()) # allows chains to run simultaneously, but needs enough RAM
brm_zone_05_dur_Social <- brm(formula = sqrt(zone_05_dur_Social) ~ Group*Sex + (1 | Fish_ID),
                                  data = Personality_wide,
                                  family = gaussian(),
                                  chains = 3,
                                  iter = 2000, warmup = 1000)
save(brm_zone_05_dur_Social, file = "../Models/brm_zone_05_dur_Social.Rdata")
load("../Models/brm_zone_05_dur_Social.Rdata")
mod_posterior_Social <- as.data.frame(brm_zone_05_dur_Social)
post_means_Social <- apply(mod_posterior_Social, 2, function(x) round(mean(x),4))

summary(brm_zone_05_dur_Social)
tab_model(brm_zone_05_dur_Social)
# Comparison with lmer model
summary(lmer_zone_05_dur_Social)
tab_model(lmer_zone_05_dur_Social)



#Comparison to the lmer models reveal results are practically the same


zone_05_post <- posterior_samples(brm_zone_05_dur_Social)
```

###Example correlation analysis 

Attempting to do some practic and wrap my head around the process
```{r}
brm_correlation_Social_Activity <- brm(cbind(scale(zone_05_dur_Social), scale(tot_dist_Activity)) ~ Group*Sex + (1 | Fish_ID),
                                  data = Personality_wide,
                                  family = gaussian(),
                                  chains = 3,
                                  iter = 2000, warmup = 1000)



save(brm_correlation_Social_Activity, file = "../Models/brm_correlation_Social_Activity.Rdata")

summary(brm_correlation_Social_Activity)

colnames(posterior_samples(brm_correlation_Social_Activity))[1:18]

Correlation_Time_Spent_Social_Dist_Travel <- posterior_samples(brm_correlation_Social_Activity)[,13] # ROSE2: always call things by their names, not their index. Reduces mistakes, makes code easier to read + more reproducible.
par(mar=c(2, 2, 3, 2))
plot(density(Correlation_Time_Spent_Social_Dist_Travel),
main="Correlation Time Spent - Total Distance Travelled",
xlab="",ylab="",cex.main=0.8)
abline(v=0,col="red",lwd=2)
abline(v=mean(Correlation_Time_Spent_Social_Dist_Travel),col="black",lwd=2)
abline(v=HPDinterval(as.mcmc(Correlation_Time_Spent_Social_Dist_Travel))[1],col="black",lty=2)
abline(v=HPDinterval(as.mcmc(Correlation_Time_Spent_Social_Dist_Travel))[2],col="black",lty=2)

#Can asume a significant positive correlation between time spent near stimulus screen during social stimulus and total distance travelled in actvity phase. Dashed lines indicate the 95% credible interval of the posterior distribution.Does not cross zero.

# For demonstrative purposes we can anyways go ahead and plot the among individual correlation of behaviors. For this we need to extract the posterior mean behavioral types (BLUP) and calculate the slope between behaviors.

#Extract BLUPS


  

#Calculating slope

#COV(X,Y ) = (CORX,Y * sqrt(VarX) * sqrt(VarY )


cov.social_dist <-
posterior_samples(Correlation_Time_Spent_Social_Dist_Travel)[,13] *
sqrt(posterior_samples(Correlation_Time_Spent_Social_Dist_Travel)[,9]^2) *
sqrt(posterior_samples(Correlation_Time_Spent_Social_Dist_Travel)[,10]^2)

var.dist <- posterior_samples(m4_brm)[,10]^2

Social_Distance_slope <- cov.social_dist / var.dist
```



