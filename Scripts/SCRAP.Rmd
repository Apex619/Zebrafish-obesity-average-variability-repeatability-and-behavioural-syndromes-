---
title: "Scrap"
author: "Hamza"
date: "19/02/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Import and subset data

First, we select a stimulus, which we want all the data for. Then with the function, we filter which videos have that stimulus in the first, second, third and fourth phase (via the time). Then we join all to create one dataset of that stimulus.
```{r}
Personality <- read.csv("./Data/Personality/ALL.csv")

# ROSE Q: have you tidied personality data to remove trials that were affected by covers falling down, etc.?
to_check <- Personality[Personality$Notes!="",] # check these ones

#HAMZA A: Apologies for the confusion. Those with the note "RE-RUN..." were fish that had to be re-run due to issues in a previous trial. Those fish are fine. Notes with a delay in time were also accounted for in Ethovision (by creating a unique setting for time). The other trials have been excluded. 

# ROSE request: fix mixing data for trial info
to_fix <- Personality[Personality$Date==""|Personality$Fish_ID=="",] # need date to know the age of the fish

# HAMZA A: Dates have been added. Sorry, again this was due to re-exporting from Ethovision and I forgot to add in certain details for the trial list. 


#Gathering all Social Data 

filter_etho(Personality, c("A","C","D","E","G","M"), ("6-9")) -> Social_Phase_1
filter_etho(Personality, c("J","K","L","P","U","X"), ("13-16")) -> Social_Phase_2
filter_etho(Personality, c("H","I","R","S","T","W"), ("20-23")) -> Social_Phase_3
filter_etho(Personality, c("B","F","N","O","Q","V"), ("27-30")) -> Social_Phase_4

Social_ALL <- bind_rows(Social_Phase_1,Social_Phase_2, Social_Phase_3, Social_Phase_4)



#Gathering all Predator Data

filter_etho(Personality, c("F","K","O","T","W","X"), ("6-9")) -> Predator_Phase_1
filter_etho(Personality, c("E","G","N","Q","R","S"), ("13-16")) -> Predator_Phase_2
filter_etho(Personality, c("B","C","M","P","U","V"), ("20-23")) -> Predator_Phase_3
filter_etho(Personality, c("A","D","H","I","J","L"), ("27-30")) -> Predator_Phase_4

Predator_ALL <- bind_rows(Predator_Phase_1,Predator_Phase_2, Predator_Phase_3, Predator_Phase_4)





#Gathering all Novel Data


filter_etho(Personality, c("B","H","J","N","P","R"), ("6-9")) -> Novel_Phase_1
filter_etho(Personality, c("A","I","M","O","V","W"), ("13-16")) -> Novel_Phase_2
filter_etho(Personality, c("D","F","G","L","Q","X"), ("20-23")) -> Novel_Phase_3
filter_etho(Personality, c("C","E","K","S","T","U"), ("27-30")) -> Novel_Phase_4

Novel_ALL <- bind_rows(Novel_Phase_1,Novel_Phase_2, Novel_Phase_3, Novel_Phase_4)





#Gathering all Aggression Data


filter_etho(Personality, c("I","L","Q","S","U","V"), ("6-9")) -> Aggression_Phase_1
filter_etho(Personality, c("B","C","D","F","H","T"), ("13-16")) -> Aggression_Phase_2
filter_etho(Personality, c("A","E","J","K","N","O"), ("20-23")) -> Aggression_Phase_3
filter_etho(Personality, c("G","M","P","R","W","X"), ("27-30")) -> Aggression_Phase_4

Aggression_ALL <- bind_rows(Aggression_Phase_1,Aggression_Phase_2, Aggression_Phase_3, Aggression_Phase_4)

#Subsetting data by control and treatment
Social_Control <- subset(Social_ALL, Social_ALL$Group == "Control") 
Social_Treatment <- subset(Social_ALL, Social_ALL$Group == "Treatment") 

Predator_Control <- subset(Predator_ALL, Predator_ALL$Group == "Control") 
Predator_Treatment <- subset(Predator_ALL, Predator_ALL$Group == "Treatment") 

Novel_Control <- subset(Novel_ALL, Novel_ALL$Group == "Control") 
Novel_Treatment <- subset(Novel_ALL, Novel_ALL$Group == "Treatment") 

Aggression_Control <- subset(Aggression_ALL, Aggression_ALL$Group == "Control") 
Aggression_Treatment <- subset(Aggression_ALL, Aggression_ALL$Group == "Treatment") 

# EXPLORATION DATA
# Acclimation <- read.csv("./Data/Personality/Acclimation.csv")
Post_assay <- read.csv("./Data/Personality/Post-assay.csv")
```

### ROSE: shorter code to Import and subset data   

```{r}
Personality <- read.csv("./Data/Personality/ALL.csv")

# making a column with a factor where the four levels correspond to the four phases
Personality$phase <-  factor(Personality$Time, levels = c("6-9", "13-16", "20-23", "27-30")) 

# making a list where each level of the list is a different phase
phases <- split(Personality, Personality$phase)

# function to apply to the four phases: 1, 2, 3, and 4
func_phase <- function(phase = 1){
    df <- phases[[phase]] # getting phase dataframe based on index (1-4)
    df$Behaviour <- df[,paste0("Phase",phase)] # getting columns that says which behaviour was in that phase
    df <- df[,!(names(df) %in% paste0("Phase", 1:4))] # removing the now-redunant Phase1,...,Phase4 columns
    return(df) # return dataframe
}

# applying function, returning a list of four dataframes
Personality_list <- lapply(1:4, function(x) func_phase(x))
Personality_df <- bind_rows(Personality_list) # stakes dataframe on top of each other

Aggression_ALL <- Personality_df[Personality_df$Behaviour == "Aggression",]
Novel_ALL <- Personality_df[Personality_df$Behaviour == "Novel",]
Predator_ALL <- Personality_df[Personality_df$Behaviour == "Predator",]
Social_ALL <- Personality_df[Personality_df$Behaviour == "Social",]

#Subsetting data by control and treatment
Social_Control <- subset(Social_ALL, Social_ALL$Group == "Control") 
Social_Treatment <- subset(Social_ALL, Social_ALL$Group == "Treatment") 

Predator_Control <- subset(Predator_ALL, Predator_ALL$Group == "Control") 
Predator_Treatment <- subset(Predator_ALL, Predator_ALL$Group == "Treatment") 

Novel_Control <- subset(Novel_ALL, Novel_ALL$Group == "Control") 
Novel_Treatment <- subset(Novel_ALL, Novel_ALL$Group == "Treatment") 

Aggression_Control <- subset(Aggression_ALL, Aggression_ALL$Group == "Control") 
Aggression_Treatment <- subset(Aggression_ALL, Aggression_ALL$Group == "Treatment") 

# EXPLORATION DATA
# Acclimation <- read.csv("../Data/Personality/Acclimation.csv")
Post_assay <- read.csv("./Data/Personality/Post-assay.csv")
```

### MAIN ANALYSIS 
1) CHECKING NORMALITY ASSUMPTIONS WITH MIXED MODELS AND A HISTOGRAM OF RESIDUALS
2) PERFORMING REPEATABILITY ANALYSIS FOR EACH GROUP AND EXTRACTING WITHIN-AND BETWEEN-INDIVIDUAL VARIANCES AFTER A Z TRANSFORMATION
3) CALCULATING DIFFERENCES BETWEEN REPEATABILITIES
4) FINAL MIXED MODEL USING LME FUNCTION
5) CALCULATING VARIANCE DIFFERENCES BETWEEN CONTROL AND TREATMENT

Exploration (Acclimation and post-stimulus); total distance traveled

```{r}


#Post assay

Model_post <- lmer(tot_dist_Activity ~ Group*Sex + (1 |Fish_ID), data = Post_assay) 
tab_model(Model_post)
hist(residuals(Model_post)) 

#Quick Visualization
Post_assay %>%
  ggplot(aes(Group, tot_dist_Activity, fill=Group)) +
  geom_violin(
    trim = FALSE,
    draw_quantiles = c(0.25, 0.5, 0.75), 
    alpha=0.5
  ) + 
  geom_point(position = "jitter", alpha = 0.7, size = 3)+
  facet_grid(~Sex)
```


Social Analysis - time spent near stimulus screen 
```{r}
#Check Normality with mixed model and then histogram of residuals

Model_Social_zone05 <- lmer(zone_05_dur ~ Group + Sex + (1 | Fish_ID), data = Social_ALL) 
tab_model(Model_Social_zone05)
hist(residuals(Model_Social_zone05)) 

Model_Social_zone052 <- lmer(zone_05_dur ~ Group*Sex + (1 | Fish_ID), data = Social_ALL) 
tab_model(Model_Social_zone052)
hist(residuals(Model_Social_zone052)) 

#Calculating repeatabilities using custom made functions
rpt_zone05(Social_Control) -> rpt_social_control
rpt_social_control
rpt_zone05(Social_Treatment) -> rpt_social_treatment
rpt_social_treatment

#Obtaining within-individual and between-individual variance 

rpt_within_zone05(Social_Control) -> within_between_social_control
within_between_social_control
rpt_within_zone05(Social_Treatment) -> within_between_social_treatment
within_between_social_treatment

#Obtaining differences between repeatabilities using custom made functions
Control_social_boot <- unlist_rptr(rpt_social_control)
Treatment_social_boot <- unlist_rptr(rpt_social_treatment) 
social_diff <- difference_boot(Treatment_social_boot,Control_social_boot)  
q_social <- quantiles_diff_boot(social_diff) #obtaining 95% CI
m_social <- mean(social_diff) #Obtaining mean
m_social
q_social

# Calculating difference in variance between control and treatment groups
Model_Social1 <- lme(zone_05_dur ~ Group*Sex-1, random = ~ 1| Fish_ID, data = Social_ALL, na.action=na.exclude) #mixed model without variance structure
summary(Model_Social1)
Model_Social2 <- lme(zone_05_dur ~ Group*Sex-1, random = ~ 1| Fish_ID, weights = varIdent(form=~1|Group), data = Social_ALL, na.action=na.exclude) #mixed model with variance structure varIdent
summary(Model_Social2)
anova(Model_Social1, Model_Social2) #calculating difference between two models to find difference in variance

#Quick Visualization
Social_ALL %>%
  ggplot(aes(Group, zone_05_dur, fill=Group)) +
  geom_violin(
    trim = FALSE,
    draw_quantiles = c(0.25, 0.5, 0.75), 
    alpha=0.5
  ) + 
  geom_point(position = "jitter", alpha = 0.7, size = 3)+
  facet_grid(~Sex)
```

Social Analysis - mean speed
```{r}
#Check Normality with mixed model and then histogram of residuals

Model_Social_speed <- lmer(mean_speed ~ Group + Sex + (1 | Fish_ID), data = Social_ALL) 
tab_model(Model_Social_speed)
hist(residuals(Model_Social_speed)) 


#Calculating repeatabilities using custom made functions
rpt_speed(Social_Control) -> rpt_social_control_speed
rpt_social_control_speed
rpt_speed(Social_Treatment) -> rpt_social_treatment_speed
rpt_social_treatment_speed

#Obtaining within-individual and between-individual variance 

rpt_within_speed(Social_Control) -> within_between_social_control_speed
within_between_social_control_speed
rpt_within_speed(Social_Treatment) -> within_between_social_treatment_speed
within_between_social_treatment_speed

#Obtaining differences between repeatabilities using custom made functions
Control_social_boot_speed <- unlist_rptr(rpt_social_control_speed)
Treatment_social_boot_speed <- unlist_rptr(rpt_social_treatment_speed) 
social_diff_speed <- difference_boot(Treatment_social_boot_speed,Control_social_boot_speed)  
q_social_speed <- quantiles_diff_boot(social_diff_speed) #obtaining 95% CI
m_social_speed <- mean(social_diff_speed) #Obtaining mean
m_social_speed
q_social_speed

# Calculating difference in variance between control and treatment groups
Model_Social1_speed <- lme(mean_speed ~ Group-1 + Sex, random = ~ 1| Fish_ID, data = Social_ALL, na.action=na.exclude) #mixed model without variance structure
summary(Model_Social1_speed)
Model_Social2_speed <- lme(mean_speed ~ Group-1 + Sex, random = ~ 1| Fish_ID, weights = varIdent(form=~1|Group), data = Social_ALL, na.action=na.exclude) #mixed model with variance structure varIdent
summary(Model_Social2_speed)
anova(Model_Social1_speed, Model_Social2_speed) #calculating difference between two models to find difference in variance

#Quick Visualization
Social_ALL %>%
  ggplot(aes(Group, mean_speed, fill=Group)) +
  geom_violin(
    trim = FALSE,
    draw_quantiles = c(0.25, 0.5, 0.75), 
    alpha=0.5
  ) + 
  geom_point(position = "jitter", alpha = 0.7, size = 3)
```

Social Analysis - total distance

```{r}
#Check Normality with mixed model and then histogram of residuals

Model_Social_tot_dist <- lmer(tot_dist ~ Group + Sex + (1 | Fish_ID), data = Social_ALL) 
tab_model(Model_Social_tot_dist)
hist(residuals(Model_Social_tot_dist)) 

Model_Social_tot_dist2 <- lmer(tot_dist ~ Group*Sex + (1 | Fish_ID), data = Social_ALL) 
tab_model(Model_Social_tot_dist2)
hist(residuals(Model_Social_tot_dist2)) 

#Calculating repeatabilities using custom made functions
rpt_tot_dist(Social_Control) -> rpt_social_control_dist
rpt_social_control_dist
rpt_tot_dist(Social_Treatment) -> rpt_social_treatment_dist
rpt_social_treatment_dist

#Obtaining within-individual and between-individual variance 

rpt_within_tot_dist(Social_Control) -> within_between_social_control_dist
within_between_social_control_dist
rpt_within_tot_dist(Social_Treatment) -> within_between_social_treatment_dist
within_between_social_treatment_dist

#Obtaining differences between repeatabilities using custom made functions
Control_social_boot_dist <- unlist_rptr(rpt_social_control_dist)
Treatment_social_boot_dist <- unlist_rptr(rpt_social_treatment_dist) 
social_diff_dist <- difference_boot(Treatment_social_boot,Control_social_boot)  
q_social_dist <- quantiles_diff_boot(social_diff_dist) #obtaining 95% CI
m_social_dist <- mean(social_diff_dist) #Obtaining mean
m_social_dist
q_social_dist

# Calculating difference in variance between control and treatment groups
Model_Social1_dist <- lme(tot_dist ~ Group*Sex-1, random = ~ 1| Fish_ID, data = Social_ALL, na.action=na.exclude) #mixed model without variance structure
summary(Model_Social1_dist)
Model_Social2_dist <- lme(tot_dist ~ Group*Sex-1, random = ~ 1| Fish_ID, weights = varIdent(form=~1|Group), data = Social_ALL, na.action=na.exclude) #mixed model with variance structure varIdent
summary(Model_Social2_dist)
anova(Model_Social1_dist, Model_Social2_dist) #calculating difference between two models to find difference in variance

#Quick Visualization
Social_ALL %>%
  ggplot(aes(Group, tot_dist, fill=Group)) +
  geom_violin(
    trim = FALSE,
    draw_quantiles = c(0.25, 0.5, 0.75), 
    alpha=0.5
  ) + 
  geom_point(position = "jitter", alpha = 0.7, size = 3)
```


Predator Analysis - time spent near stimulus screen 
```{r}
#Check Normality with mixed model and then histogram of residuals

Model_Predator_zone05 <- lmer(zone_05_dur ~ Group + Sex + (1 | Fish_ID), data = Predator_ALL) 
tab_model(Model_Predator_zone05)
hist(residuals(Model_Predator_zone05)) 


#Calculating repeatabilities using custom made functions
rpt_zone05(Predator_Control) -> rpt_predator_control
rpt_predator_control
rpt_zone05(Predator_Treatment) -> rpt_predator_treatment
rpt_predator_treatment

#Obtaining within-individual and between-individual variance 

rpt_within_zone05(Predator_Control) -> within_between_predator_control
within_between_predator_control
rpt_within_zone05(Predator_Treatment) -> within_between_predator_treatment
within_between_predator_treatment

#Obtaining differences between repeatabilities using custom made functions
Control_predator_boot <- unlist_rptr(rpt_predator_control)
Treatment_predator_boot <- unlist_rptr(rpt_predator_treatment) 
predator_diff <- difference_boot(Treatment_predator_boot,Control_predator_boot)  
q_predator <- quantiles_diff_boot(predator_diff) #obtaining 95% CI
m_predator <- mean(positive_diff) #Obtaining mean
m_predator
q_predator

# Calculating difference in variance between control and treatment groups
Model_Predator1 <- lme(zone_05_dur ~ Group-1 + Sex, random = ~ 1| Fish_ID, data = Predator_ALL, na.action=na.exclude) #mixed model without variance structure
summary(Model_Predator1)
Model_Predator2 <- lme(zone_05_dur ~ Group-1 + Sex, random = ~ 1| Fish_ID, weights = varIdent(form=~1|Group), data = Predator_ALL, na.action=na.exclude) #mixed model with variance structure varIdent
summary(Model_Predator2)
anova(Model_Predator1, Model_Predator2) #calculating difference between two models to find difference in variance

#Quick Visualization
Predator_ALL %>%
  ggplot(aes(Group, zone_05_dur, fill=Group)) +
  geom_violin(
    trim = FALSE,
    draw_quantiles = c(0.25, 0.5, 0.75), 
    alpha=0.5
  ) + 
  geom_point(position = "jitter", alpha = 0.7, size = 3)
```

Predator Analysis - mean speed
```{r}
#Check Normality with mixed model and then histogram of residuals

Model_Predator_speed <- lmer(mean_speed ~ Group + Sex + (1 | Fish_ID), data = Predator_ALL) 
tab_model(Model_Predator_speed)
hist(residuals(Model_Predator_speed)) 


#Calculating repeatabilities using custom made functions
rpt_speed(Predator_Control) -> rpt_predator_control_speed
rpt_predator_control_speed
rpt_speed(Predator_Treatment) -> rpt_predator_treatment_speed
rpt_predator_treatment_speed

#Obtaining within-individual and between-individual variance 

rpt_within_speed(Predator_Control) -> within_between_predator_control_speed
within_between_predator_control_speed
rpt_within_speed(Predator_Treatment) -> within_between_predator_treatment_speed
within_between_predator_treatment_speed

#Obtaining differences between repeatabilities using custom made functions
Control_predator_boot_speed <- unlist_rptr(rpt_predator_control_speed)
Treatment_predator_boot_speed <- unlist_rptr(rpt_predator_treatment_speed) 
predator_diff_speed <- difference_boot(Treatment_predator_boot_speed,Control_predator_boot_speed)  
q_predator_speed <- quantiles_diff_boot(predator_diff_speed) #obtaining 95% CI
m_predator_speed <- mean(predator_diff_speed) #Obtaining mean
m_predator_speed
q_predator_speed

# Calculating difference in variance between control and treatment groups
Model_Predator1_speed <- lme(mean_speed ~ Group-1 + Sex, random = ~ 1| Fish_ID, data = Predator_ALL, na.action=na.exclude) #mixed model without variance structure
summary(Model_Predator1_speed)
Model_Predator2_speed <- lme(mean_speed ~ Group-1 + Sex, random = ~ 1| Fish_ID, weights = varIdent(form=~1|Group), data = Predator_ALL, na.action=na.exclude) #mixed model with variance structure varIdent
summary(Model_Predator2_speed)
anova(Model_Predator1_speed, Model_Predator2_speed) #calculating difference between two models to find difference in variance

#Quick Visualization
Predator_ALL %>%
  ggplot(aes(Group, mean_speed, fill=Group)) +
  geom_violin(
    trim = FALSE,
    draw_quantiles = c(0.25, 0.5, 0.75), 
    alpha=0.5
  ) + 
  geom_point(position = "jitter", alpha = 0.7, size = 3)
```

Predator Analysis - total distance

```{r}
#Check Normality with mixed model and then histogram of residuals

Model_Predator_tot_dist <- lmer(tot_dist ~ Group + Sex + (1 | Fish_ID), data = Predator_ALL) 
tab_model(Model_Predator_tot_dist)
hist(residuals(Model_Predator_tot_dist)) 

Model_Predator_tot_dist2 <- lmer(tot_dist ~ Group*Sex + (1 | Fish_ID), data = Predator_ALL) 
tab_model(Model_Predator_tot_dist2)
hist(residuals(Model_Predator_tot_dist2)) 

#Calculating repeatabilities using custom made functions
rpt_tot_dist(Predator_Control) -> rpt_predator_control_dist
rpt_predator_control_dist
rpt_tot_dist(Predator_Treatment) -> rpt_predator_treatment_dist
rpt_predator_treatment_dist

#Obtaining within-individual and between-individual variance 

rpt_within_tot_dist(Predator_Control) -> within_between_predator_control_dist
within_between_predator_control_dist
rpt_within_tot_dist(Predator_Treatment) -> within_between_predator_treatment_dist
within_between_predator_treatment_dist

#Obtaining differences between repeatabilities using custom made functions
Control_predator_boot_dist <- unlist_rptr(rpt_predator_control_dist)
Treatment_predator_boot_dist <- unlist_rptr(rpt_predator_treatment_dist) 
predator_diff_dist <- difference_boot(Treatment_predator_boot,Control_predator_boot)  
q_predator_dist <- quantiles_diff_boot(predator_diff_dist) #obtaining 95% CI
m_predator_dist <- mean(predator_diff_dist) #Obtaining mean
m_predator_dist
q_predator_dist

# Calculating difference in variance between control and treatment groups
Model_Predator1_dist <- lme(tot_dist ~ Group*Sex-1, random = ~ 1| Fish_ID, data = Predator_ALL, na.action=na.exclude) #mixed model without variance structure
summary(Model_Predator1_dist)
Model_Predator2_dist <- lme(tot_dist ~ Group*Sex-1, random = ~ 1| Fish_ID, weights = varIdent(form=~1|Group), data = Predator_ALL, na.action=na.exclude) #mixed model with variance structure varIdent
summary(Model_Predator2_dist)
anova(Model_Predator1_dist, Model_Predator2_dist) #calculating difference between two models to find difference in variance

#Quick Visualization
Predator_ALL %>%
  ggplot(aes(Group, tot_dist, fill=Group)) +
  geom_violin(
    trim = FALSE,
    draw_quantiles = c(0.25, 0.5, 0.75), 
    alpha=0.5
  ) + 
  geom_point(position = "jitter", alpha = 0.7, size = 3)
```


Novel Analysis - time spent near stimulus screen 
```{r}
#Check Normality with mixed model and then histogram of residuals

Model_Novel_zone05 <- lmer(zone_05_dur ~ Group + Sex + (1 | Fish_ID), data = Novel_ALL) 
tab_model(Model_Novel_zone05)
hist(residuals(Model_Novel_zone05)) #data skewed, needs transformation

Model_Novel_zone052 <- lmer(sqrt(zone_05_dur) ~ Group + Sex + (1 | Fish_ID), data = Novel_ALL) 
tab_model(Model_Novel_zone052)
hist(residuals(Model_Novel_zone052))


#Calculating repeatabilities using custom made functions
rpt_zone05(Novel_Control) -> rpt_novel_control
rpt_novel_control
rpt_zone05(Novel_Treatment) -> rpt_novel_treatment
rpt_novel_treatment

#Obtaining within-individual and between-individual variance 

rpt_within_zone05(Novel_Control) -> within_between_novel_control
within_between_novel_control
rpt_within_zone05(Novel_Treatment) -> within_between_novel_treatment
within_between_novel_treatment

#Obtaining differences between repeatabilities using custom made functions
Control_novel_boot <- unlist_rptr(rpt_novel_control)
Treatment_novel_boot <- unlist_rptr(rpt_novel_treatment) 
novel_diff <- difference_boot(Control_novel_boot,Treatment_novel_boot)  
q_novel <- quantiles_diff_boot(novel_diff) #obtaining 95% CI
m_novel <- mean(novel_diff) #Obtaining mean
m_novel
q_novel

# Calculating difference in variance between control and treatment groups
Model_Novel1 <- lme(sqrt(zone_05_dur) ~ Group-1 + Sex, random = ~ 1| Fish_ID, data = Novel_ALL, na.action=na.exclude) #mixed model without variance structure
summary(Model_Novel1)
Model_Novel2 <- lme(sqrt(zone_05_dur) ~ Group-1 + Sex, random = ~ 1| Fish_ID, weights = varIdent(form=~1|Group), data = Novel_ALL, na.action=na.exclude) #mixed model with variance structure varIdent
summary(Model_Novel2)
anova(Model_Novel1, Model_Novel2) #calculating difference between two models to find difference in variance

#Quick Visualization
Novel_ALL %>%
  ggplot(aes(Group, zone_05_dur, fill=Group)) +
  geom_violin(
    trim = FALSE,
    draw_quantiles = c(0.25, 0.5, 0.75), 
    alpha=0.5
  ) + 
  geom_point(position = "jitter", alpha = 0.7, size = 3)
```

Novel Analysis - mean speed
```{r}
#Check Normality with mixed model and then histogram of residuals

Model_Novel_speed <- lmer(mean_speed ~ Group + Sex + (1 | Fish_ID), data = Novel_ALL) 
tab_model(Model_Novel_speed)
hist(residuals(Model_Novel_speed)) 


#Calculating repeatabilities using custom made functions
rpt_speed(Novel_Control) -> rpt_novel_control_speed
rpt_novel_control_speed
rpt_speed(Novel_Treatment) -> rpt_novel_treatment_speed
rpt_novel_treatment_speed

#Obtaining within-individual and between-individual variance 

rpt_within_speed(Novel_Control) -> within_between_novel_control_speed
within_between_novel_control_speed
rpt_within_speed(Novel_Treatment) -> within_between_novel_treatment_speed
within_between_novel_treatment_speed

#Obtaining differences between repeatabilities using custom made functions
Control_novel_boot_speed <- unlist_rptr(rpt_novel_control_speed)
Treatment_novel_boot_speed <- unlist_rptr(rpt_novel_treatment_speed) 
novel_diff_speed <- difference_boot(Control_novel_boot_speed,Treatment_novel_boot_speed)  
q_novel_speed <- quantiles_diff_boot(novel_diff_speed) #obtaining 95% CI
m_novel_speed <- mean(novel_diff_speed) #Obtaining mean
m_novel_speed
q_novel_speed

# Calculating difference in variance between control and treatment groups
Model_Novel1_speed <- lme(mean_speed ~ Group-1 + Sex, random = ~ 1| Fish_ID, data = Novel_ALL, na.action=na.exclude) #mixed model without variance structure
summary(Model_Novel1_speed)
Model_Novel2_speed <- lme(mean_speed ~ Group-1 + Sex, random = ~ 1| Fish_ID, weights = varIdent(form=~1|Group), data = Novel_ALL, na.action=na.exclude) #mixed model with variance structure varIdent
summary(Model_Novel2_speed)
anova(Model_Novel1_speed, Model_Novel2_speed) #calculating difference between two models to find difference in variance

#Quick Visualization
Novel_ALL %>%
  ggplot(aes(Group, mean_speed, fill=Group)) +
  geom_violin(
    trim = FALSE,
    draw_quantiles = c(0.25, 0.5, 0.75), 
    alpha=0.5
  ) + 
  geom_point(position = "jitter", alpha = 0.7, size = 3)
```

Novel Analysis - total distance

```{r}
#Check Normality with mixed model and then histogram of residuals

Model_Novel_tot_dist <- lmer(tot_dist ~ Group + Sex + (1 | Fish_ID), data = Novel_ALL) 
tab_model(Model_Novel_tot_dist)
hist(residuals(Model_Novel_tot_dist)) 

Model_Novel_tot_dist2 <- lmer(tot_dist ~ Group*Sex + (1 | Fish_ID), data = Novel_ALL) 
tab_model(Model_Novel_tot_dist2)
hist(residuals(Model_Novel_tot_dist2)) 

#Calculating repeatabilities using custom made functions
rpt_tot_dist(Novel_Control) -> rpt_novel_control_dist
rpt_novel_control_dist
rpt_tot_dist(Novel_Treatment) -> rpt_novel_treatment_dist
rpt_novel_treatment_dist

#Obtaining within-individual and between-individual variance 

rpt_within_tot_dist(Novel_Control) -> within_between_novel_control_dist
within_between_novel_control_dist
rpt_within_tot_dist(Novel_Treatment) -> within_between_novel_treatment_dist
within_between_novel_treatment_dist

#Obtaining differences between repeatabilities using custom made functions
Control_novel_boot_dist <- unlist_rptr(rpt_novel_control_dist)
Treatment_novel_boot_dist <- unlist_rptr(rpt_novel_treatment_dist) 
novel_diff_dist <- difference_boot(Treatment_novel_boot,Control_novel_boot)  
q_novel_dist <- quantiles_diff_boot(novel_diff_dist) #obtaining 95% CI
m_novel_dist <- mean(novel_diff_dist) #Obtaining mean
m_novel_dist
q_novel_dist

# Calculating difference in variance between control and treatment groups
Model_Novel1_dist <- lme(tot_dist ~ Group*Sex-1, random = ~ 1| Fish_ID, data = Novel_ALL, na.action=na.exclude) #mixed model without variance structure
summary(Model_Novel1_dist)
Model_Novel2_dist <- lme(tot_dist ~ Group*Sex-1, random = ~ 1| Fish_ID, weights = varIdent(form=~1|Group), data = Novel_ALL, na.action=na.exclude) #mixed model with variance structure varIdent
summary(Model_Novel2_dist)
anova(Model_Novel1_dist, Model_Novel2_dist) #calculating difference between two models to find difference in variance

#Quick Visualization
Novel_ALL %>%
  ggplot(aes(Group, tot_dist, fill=Group)) +
  geom_violin(
    trim = FALSE,
    draw_quantiles = c(0.25, 0.5, 0.75), 
    alpha=0.5
  ) + 
  geom_point(position = "jitter", alpha = 0.7, size = 3)
```

Aggression Analysis - time spent near stimulus screen 
```{r}
#Check Normality with mixed model and then histogram of residuals

Model_Aggression_zone05 <- lmer(zone_05_dur ~ Group + Sex + (1 | Fish_ID), data = Aggression_ALL) 
tab_model(Model_Aggression_zone05)
hist(residuals(Model_Aggression_zone05)) 


#Calculating repeatabilities using custom made functions
rpt_zone05(Aggression_Control) -> rpt_aggression_control
rpt_aggression_control
rpt_zone05(Aggression_Treatment) -> rpt_aggression_treatment
rpt_aggression_treatment

#Obtaining within-individual and between-individual variance 

rpt_within_zone05(Aggression_Control) -> within_between_aggression_control
within_between_aggression_control
rpt_within_zone05(Aggression_Treatment) -> within_between_aggression_treatment
within_between_aggression_treatment

#Obtaining differences between repeatabilities using custom made functions
Control_aggression_boot <- unlist_rptr(rpt_aggression_control)
Treatment_aggression_boot <- unlist_rptr(rpt_aggression_treatment) 
aggression_diff <- difference_boot(Treatment_aggression_boot,Control_aggression_boot)  
q_aggression <- quantiles_diff_boot(aggression_diff) #obtaining 95% CI
m_aggression <- mean(aggression_diff) #Obtaining mean
m_aggression
q_aggression

# Calculating difference in variance between control and treatment groups
Model_Aggression1 <- lme(zone_05_dur ~ Group-1 + Sex, random = ~ 1| Fish_ID, data = Aggression_ALL, na.action=na.exclude) #mixed model without variance structure
summary(Model_Aggression1)
Model_Aggression2 <- lme(zone_05_dur ~ Group-1 + Sex, random = ~ 1| Fish_ID, weights = varIdent(form=~1|Group), data = Aggression_ALL, na.action=na.exclude) #mixed model with variance structure varIdent
summary(Model_Aggression2)
anova(Model_Aggression1, Model_Aggression2) #calculating difference between two models to find difference in variance

#Quick Visualization
Aggression_ALL %>%
  ggplot(aes(Group, zone_05_dur, fill=Group)) +
  geom_violin(
    trim = FALSE,
    draw_quantiles = c(0.25, 0.5, 0.75), 
    alpha=0.5
  ) + 
  geom_point(position = "jitter", alpha = 0.7, size = 3)
```

Aggression Analysis - mean speed
```{r}
#Check Normality with mixed model and then histogram of residuals

Model_Aggression_speed <- lmer(mean_speed ~ Group + Sex + (1 | Fish_ID), data = Aggression_ALL) 
tab_model(Model_Aggression_speed)
hist(residuals(Model_Aggression_speed)) 


#Calculating repeatabilities using custom made functions
rpt_speed(Aggression_Control) -> rpt_aggression_control_speed
rpt_aggression_control_speed
rpt_speed(Aggression_Treatment) -> rpt_aggression_treatment_speed
rpt_aggression_treatment_speed

#Obtaining within-individual and between-individual variance 

rpt_within_speed(Aggression_Control) -> within_between_aggression_control_speed
within_between_aggression_control_speed
rpt_within_speed(Aggression_Treatment) -> within_between_aggression_treatment_speed
within_between_aggression_treatment_speed

#Obtaining differences between repeatabilities using custom made functions
Control_aggression_boot_speed <- unlist_rptr(rpt_aggression_control_speed)
Treatment_aggression_boot_speed <- unlist_rptr(rpt_aggression_treatment_speed) 
aggression_diff_speed <- difference_boot(Control_aggression_boot_speed,Treatment_aggression_boot_speed)  
q_aggression_speed <- quantiles_diff_boot(aggression_diff_speed) #obtaining 95% CI
m_aggression_speed <- mean(aggression_diff_speed) #Obtaining mean
m_aggression_speed
q_aggression_speed

# Calculating difference in variance between control and treatment groups
Model_Aggression1_speed <- lme(mean_speed ~ Group-1 + Sex, random = ~ 1| Fish_ID, data = Aggression_ALL, na.action=na.exclude) #mixed model without variance structure
summary(Model_Aggression1_speed)
Model_Aggression2_speed <- lme(mean_speed ~ Group-1 + Sex, random = ~ 1| Fish_ID, weights = varIdent(form=~1|Group), data = Aggression_ALL, na.action=na.exclude) #mixed model with variance structure varIdent
summary(Model_Aggression2_speed)
anova(Model_Aggression1_speed, Model_Aggression2_speed) #calculating difference between two models to find difference in variance

#Quick Visualization
Aggression_ALL %>%
  ggplot(aes(Group, mean_speed, fill=Group)) +
  geom_violin(
    trim = FALSE,
    draw_quantiles = c(0.25, 0.5, 0.75), 
    alpha=0.5
  ) + 
  geom_point(position = "jitter", alpha = 0.7, size = 3)
```

Aggression Analysis - total distance

```{r}
#Check Normality with mixed model and then histogram of residuals

Model_Aggression_tot_dist <- lmer(tot_dist ~ Group + Sex + (1 | Fish_ID), data = Aggression_ALL) 
tab_model(Model_Aggression_tot_dist)
hist(residuals(Model_Aggression_tot_dist)) 

Model_Aggression_tot_dist2 <- lmer(tot_dist ~ Group*Sex + (1 | Fish_ID), data = Aggression_ALL) 
tab_model(Model_Aggression_tot_dist2)
hist(residuals(Model_Aggression_tot_dist2)) 

#Calculating repeatabilities using custom made functions
rpt_tot_dist(Aggression_Control) -> rpt_aggression_control_dist
rpt_aggression_control_dist
rpt_tot_dist(Aggression_Treatment) -> rpt_aggression_treatment_dist
rpt_aggression_treatment_dist

#Obtaining within-individual and between-individual variance 

rpt_within_tot_dist(Aggression_Control) -> within_between_aggression_control_dist
within_between_aggression_control_dist
rpt_within_tot_dist(Aggression_Treatment) -> within_between_aggression_treatment_dist
within_between_aggression_treatment_dist

#Obtaining differences between repeatabilities using custom made functions
Control_aggression_boot_dist <- unlist_rptr(rpt_aggression_control_dist)
Treatment_aggression_boot_dist <- unlist_rptr(rpt_aggression_treatment_dist) 
aggression_diff_dist <- difference_boot(Treatment_aggression_boot,Control_aggression_boot)  
q_aggression_dist <- quantiles_diff_boot(aggression_diff_dist) #obtaining 95% CI
m_aggression_dist <- mean(aggression_diff_dist) #Obtaining mean
m_aggression_dist
q_aggression_dist

# Calculating difference in variance between control and treatment groups
Model_Aggression1_dist <- lme(tot_dist ~ Group*Sex-1, random = ~ 1| Fish_ID, data = Aggression_ALL, na.action=na.exclude) #mixed model without variance structure
summary(Model_Aggression1_dist)
Model_Aggression2_dist <- lme(tot_dist ~ Group*Sex-1, random = ~ 1| Fish_ID, weights = varIdent(form=~1|Group), data = Aggression_ALL, na.action=na.exclude) #mixed model with variance structure varIdent
summary(Model_Aggression2_dist)
anova(Model_Aggression1_dist, Model_Aggression2_dist) #calculating difference between two models to find difference in variance

#Quick Visualization
Aggression_ALL %>%
  ggplot(aes(Group, tot_dist, fill=Group)) +
  geom_violin(
    trim = FALSE,
    draw_quantiles = c(0.25, 0.5, 0.75), 
    alpha=0.5
  ) + 
  geom_point(position = "jitter", alpha = 0.7, size = 3)
```

## ROSE: looking at residuals
```{r}
# load("~/Dropbox/Shinichi/Postdoc/F0_Chapter_Analysis/Scripts/myEnvironment.RData")
hist(residuals(Model_acclimation))                                    
hist(residuals(Model_post))                                           
hist(residuals(Model_Social_zone05))  # negatively skewed                                 
hist(residuals(Model_Social_zone052)) # negatively skewed                                   
hist(residuals(Model_Social_speed))   # positively skewed                                
hist(residuals(Model_Social_tot_dist))# positively skewed                                 
hist(residuals(Model_Social_tot_dist2))# positively skewed                               
hist(residuals(Model_Predator_zone05))# positively skewed                                
hist(residuals(Model_Predator_speed))                                 
hist(residuals(Model_Predator_tot_dist))                              
hist(residuals(Model_Predator_tot_dist2))                             
hist(residuals(Model_Novel_zone05)) # positively skewed
hist(residuals(Model_Novel_zone052)) # tails too fat                                  
hist(residuals(Model_Novel_speed)) # tails too skinny                                   
hist(residuals(Model_Novel_tot_dist)) # negatively skewed                                 
hist(residuals(Model_Novel_tot_dist2)) # negatively skewed                                
hist(residuals(Model_Aggression_zone05))                              
hist(residuals(Model_Aggression_speed)) # tails too thin                             
hist(residuals(Model_Aggression_tot_dist)) # tails too thin                             
hist(residuals(Model_Aggression_tot_dist2))  # tails too thin  
```

###Example correlation analysis 

Attempting to do some practic and wrap my head around the process
```{r}
brm_correlation_Social_Activity <- brm(cbind(scale(zone_05_dur_Social), scale(tot_dist_Activity)) ~ Group*Sex + (1 | Fish_ID),
                                  data = Personality_wide,
                                  family = gaussian(),
                                  chains = 3,
                                  iter = 2000, warmup = 1000)



save(brm_correlation_Social_Activity, file = "../Models/brm_correlation_Social_Activity.Rdata")

summary(brm_correlation_Social_Activity)

colnames(posterior_samples(brm_correlation_Social_Activity))[1:18]

Correlation_Time_Spent_Social_Dist_Travel <- posterior_samples(brm_correlation_Social_Activity)[,13] # ROSE2: always call things by their names, not their index. Reduces mistakes, makes code easier to read + more reproducible.
par(mar=c(2, 2, 3, 2))
plot(density(Correlation_Time_Spent_Social_Dist_Travel),
main="Correlation Time Spent - Total Distance Travelled",
xlab="",ylab="",cex.main=0.8)
abline(v=0,col="red",lwd=2)
abline(v=mean(Correlation_Time_Spent_Social_Dist_Travel),col="black",lwd=2)
abline(v=HPDinterval(as.mcmc(Correlation_Time_Spent_Social_Dist_Travel))[1],col="black",lty=2)
abline(v=HPDinterval(as.mcmc(Correlation_Time_Spent_Social_Dist_Travel))[2],col="black",lty=2)

#Can asume a significant positive correlation between time spent near stimulus screen during social stimulus and total distance travelled in actvity phase. Dashed lines indicate the 95% credible interval of the posterior distribution.Does not cross zero.

# For demonstrative purposes we can anyways go ahead and plot the among individual correlation of behaviors. For this we need to extract the posterior mean behavioral types (BLUP) and calculate the slope between behaviors.

#Extract BLUPS


  

#Calculating slope

#COV(X,Y ) = (CORX,Y * sqrt(VarX) * sqrt(VarY )


cov.social_dist <-
posterior_samples(Correlation_Time_Spent_Social_Dist_Travel)[,13] *
sqrt(posterior_samples(Correlation_Time_Spent_Social_Dist_Travel)[,9]^2) *
sqrt(posterior_samples(Correlation_Time_Spent_Social_Dist_Travel)[,10]^2)

var.dist <- posterior_samples(m4_brm)[,10]^2

Social_Distance_slope <- cov.social_dist / var.dist
```


### Run lmer models for chosen behaviour

```{r}
# Chosen variables: total distance for activity, zone_05_dur for stimulus phases

# ROSE: you could modify the function so you can do it all at once:
func_mod_behav_vars  <- function(var,df = Personality_wide){
  mod <- lmer(df[,var] ~ Group*Sex + (1 | Fish_ID), data = df)
  if(str_detect(var, "Novel")){ # if the variable = Novel, we will square-root the variable
    mod <- lmer(sqrt(df[,var]) ~ Group*Sex + (1 | Fish_ID), data = df) 
  }

  return(mod) 
  
}

behav_vars <- c("zone_05_dur_Social", "zone_05_dur_Predator", "zone_05_dur_Novel", "zone_05_dur_Aggression", "tot_dist_Activity") # including novel and changing activity from zone_05_dur to tot_dist_Activity
mod_list_5behav <- lapply(behav_vars, function(x) func_mod_behav_vars(x)) 
names(mod_list_5behav) <- behav_vars

lmer_zone_05_dur_Social <- lmer(zone_05_dur_Social ~ Group*Sex + (1 | Fish_ID), data = Personality_wide) #Extra model to check

fixef(lmer_zone_05_dur_Social) == fixef(mod_list_5behav$zone_05_dur_Social) # they're the same

#lmer_zone_05_dur_Novel <- lmer(sqrt(zone_05_dur_Novel) ~ Group*Sex + (1 | Fish_ID), data = Personality_wide) # Extra model to check

```

### Extract BLUPs from lmer models and plot fitted versus. predicted

-   make a dataframe with the model parameters\
-   fitted = the actual measured behaviors
-   predicted = the model predictions, calculated according to the below equation:

$$y_{ij} = \beta_0 + \text{ID}_j + \beta_1(\text{treatment})+ \beta_2(\text{male}) + \beta_3(\text{treatment}\cdot\text{male}) + e_i$$

$$\text{ID} \sim \text{N}(0,\sigma^2_{\text{ID}})$$ $$e \sim \text{N}(0,\sigma^2_{\text{e}})$$

```{r}

func_fitted_predicted_lmer <- function(variable = behav_vars[1]){ 
  mod <- mod_list_5behav[[variable]] # using the variable name to get the model
  #getting population parameters
  betas <- fixef(mod)
b0 <- betas[1]
b1 <- betas[2]
b2 <- betas[3]
b3 <- betas[4]
# getting blups
blups <- data.frame(ranef(mod))
round(mean(blups$condval)) # average of blups = 0
# finding the treatment and male value for each fish_ID
fish_ID <- as.character(blups$grp)
# need to match fish_ID ID with their info
pos <- match(fish_ID, Personality_wide$Fish_ID)
mod_pars <- data.frame(fish_ID, b0, ID = blups$condval, b1, b2, b3, treatment = ifelse(Personality_wide$Group[pos] == "Treatment",1,0), male = ifelse(Personality_wide$Sex[pos]=="male",1,0)) %>% mutate(predicted = b0 + ID + b1*treatment + b2*male + b3*(treatment*male))
(Personality_wide$Fish_ID[pos] == fish_ID) # all TRUE
# finding predicted values
pos <- match(Personality_wide$Fish_ID, mod_pars$fish_ID)
(mod_pars$fish_ID[pos]==Personality_wide$Fish_ID) # all TRUE
fitted_predicted <- mod_pars[pos,] 
fitted_predicted$fitted<- Personality_wide[,variable]
str_detect(variable, "Novel") #test
if(str_detect(variable, "Novel")){
  fitted_predicted$fitted <- sqrt(fitted_predicted$fitted)
}

fitted_predicted$variable_name <- variable
fitted_predicted$residuals <- fitted_predicted$fitted - fitted_predicted$predicted
return(fitted_predicted) 
}

# plot(resid(mod), fitted_predicted$residuals) Checking


# applying this function to our variables
fitted_predicted_lmer_list <- lapply(behav_vars, function(x) func_fitted_predicted_lmer(variable = x))
names(fitted_predicted_lmer_list) <- behav_vars

fitted_predicted_lmer_list$zone_05_dur_Novel$predicted <- sqrt(fitted_predicted_lmer_list$zone_05_dur_Novel$predicted) #HAMZA: Or I can do this after we have run lapply? Is an extra step which is not ideal 

# Function to plot fitted vs. predicted and calculate R2
func_fitted_predicted_plots <- function(df =
                                          fitted_predicted_lmer_list[[2]]){
  behav<- gsub(".*dur\\_|.*dist\\_", "", df$variable_name[1]) 
  
  R2<- cor(df$fitted, df$predicted)^2 %>% round(3)
  
  plot<- ggplot(df)+
    theme_classic()+
    geom_point(aes(x=fitted, y=predicted))+
    labs(x=df$variable_name[1],
         title=behav,subtitle=paste0("R2 = ", R2))
  
  return(plot)
}

plot_list_behavs <- lapply(fitted_predicted_lmer_list, function(x) func_fitted_predicted_plots(x))

plot_list_behavs[[1]]
plot_list_behavs[[2]]
plot_list_behavs[[3]]
plot_list_behavs[[4]]
plot_list_behavs[[5]]

```

### Repeat the above steps in brm (which uses stan), and compare the results to the lmer models

```{r}
#Here To-do:

# - Write a function that will input your brm model object, and output two things: (1) the posterior distributions of population parameters; (2) the fitted and predicted values for posterior means.
behav_vars <- c("zone_05_dur_Social", "zone_05_dur_Predator", "zone_05_dur_Novel", "zone_05_dur_Aggression", "tot_dist_Activity") 


load("./Models/mod_list_brms.Rdata")

options(mc.scores = parallel::detectCores())


func_brm_mod <- function(var, df = Personality_wide){
  df$response <- df[,var] # formula argument relies entirely on the data argument, so you can't just call the columns directly

  if(str_detect(var, "Novel")){ 
    brm <- brm(formula = sqrt(response) ~ Group*Sex + (1 | Fish_ID), 
                                  data = df,
                                  family = gaussian(),
                                  chains = 3,
                                 iter = 2000, warmup = 1000)
  }else{ # ROSE TIP: before, for novel, you had to run two models. Now, you only run one (one of the other). Because baysian models take a while to run, this will speed up the function.
      brm <- brm(formula = response ~ Group*Sex + (1 | Fish_ID), 
                                  data = df,
                                  family = gaussian(),
                                  chains = 3,
                                 iter = 2000, warmup = 1000)
  }

  return(brm)
}


# mod_list_brms <- lapply(behav_vars, function(x) func_brm_mod(x))
# names(mod_list_brms) <- behav_vars
# save(mod_list_brms, file = "./Models/mod_list_brms.Rdata")

# Rose's tips:

func_process_mod_brm <- function(variable = behav_vars[1]){
    mod <- mod_list_brms[[variable]]
    
  mod_posterior <- as.data.frame(mod)
  pop_posterior <- select(mod_posterior,!contains(c("r_Fish_ID", "lp"))) #We don't want to get rid of the variance component ! Hence why "r_Fish_ID" and not "Fish_ID"
  
  b0 <- pop_posterior[,"b_Intercept"] 
  b1 <- pop_posterior[, "b_GroupTreatment"]
  b2 <- pop_posterior[, "b_Sexmale"]
 # b3 <- pop_posterior[, "b_GroupTreatment.Sexmale"] # ROSE: this is an error
  b3 <- pop_posterior[, "b_GroupTreatment.Sexmale"] #I had to change it back as there's no ":", only a "."
  sigma_e <- pop_posterior[, "sigma"]

  sigma_ID <- pop_posterior[, "sd_Fish_ID__Intercept"]
  
  pop_posterior <- data.frame(b0, b1, b2, b3, sigma_e, sigma_ID)
  
  # next, get the posterior means, as you did above
   post_means <- apply(mod_posterior, 2, function(x) mean(x)) # except we don't round because we're using these in subsequent calculations
  
  # to make fitted_predicted, the logic is as follows:
   
   # we have:
   fitted <- Personality_wide[,c("Fish_ID", "Sex", "Group", variable)]
   names(fitted)[names(fitted)==variable] <- "fitted" 
   if(str_detect(variable, "Novel")){
     fitted$fitted <- sqrt(fitted$fitted)
   }
   
   
 
  
   
   # and we need to get what the model predicted. So you need to solve the model equation from line 219, predicted = B0 + individual_difference + B1*treatment + B2*male + B3*treatment*male.
   
   # to do this calculation, make three more columns from 'fitted': a column of 1s and 0s for treatment,a column of 1s and 0s for male, and a column of individual_difference, which you will get by matching the Fish_ID in each row to the mean BLUP from post_means

   # ROSE:
   blups <- post_means[str_detect(names(post_means), "r_Fish_ID")] # here are your individual differences
   # now use gsub to rename them so the name is just the fish_ID
   names(blups) # see how these are all in the format r_Fish_ID[aXXXX,Intercept]? You need to get them to all be aXXXX, then you can match them up with the fish_IDs in the fitted dataframe.
   
names(blups) <- gsub(".*Fish_ID.", "",  names(blups))
names(blups) <- gsub(".Intercept.", "", names(blups))
# I did this in two steps because I'm not sure how to keep the middle of the string without ruining the entire thing :/ 
names(blups) # Double checking to make sure we have renamed correctly

fish_ID <- names(blups) 
  
  
  # ROSE tip: when you get stuck doing something complicated, it's always best to break it down into little steps (rather than the one line below)
  
  # step one: get the order of fish in the fitted dataset
  fitted_fish <- fitted$Fish_ID
  
  # step two: get an indexing vector to put the indiv differences in the same order as fish in the fitted dataset
  pos <- match(fitted_fish, fish_ID) # for match, the first argument is the reference, and the second argument is the one you are retrieving an index for. Double check the output and if it correct ! Is it working in the direction we want !
  
  # always check that the matching is correct
  fish_ID[pos] == fitted_fish # all TRUE
  # you can also check like this:
  sum(fish_ID[pos] == fitted_fish) == length(fitted_fish)
  
  # step three: get a vector of the individual differences
  ID <- blups[pos]
  # checking this is right
  names(ID) == fitted_fish
  
  # step four: get columns for the categorical variables of 'male', 'treatment', and 'treatment*male'
  male <- ifelse(fitted$Sex=="male",1,0) #Has to be lower case
  treatment <- ifelse(fitted$Group=="Treatment",1,0)
  treatment.male <- ifelse(fitted$Group=="Treatment"&fitted$Sex=="male",1,0) #Changed to lower case
  
  # step five: get the posterior mean estimates for your model coefficients: intercept male contrast treatment contrast and male + treatment interaction
  b0 <- post_means["b_Intercept"] 
  b1 <- post_means["b_GroupTreatment"]
  b2 <- post_means["b_Sexmale"]
  b3 <- post_means["b_GroupTreatment.Sexmale"] #Only works with "."
  
  # step six: do the maths to get your predicted values
  predicted <- b0 + ID + b1*treatment + b2*male + b3*treatment.male
  
  # step seven: make your dataframe for export
  fitted_predicted <- data.frame(fish_ID = fitted_fish, 
                                 fitted = fitted$fitted,
                                 b0, ID, b1, b2, b3,
                                 treatment, male, 
                                 predicted, 
                                 variable_name = variable, residuals = fitted$fitted - predicted
                                 )

   
  return(list(pop_posterior, fitted_predicted))
  
}


# Next: apply func_process_mod() to all your variables 
fitted_process_brm_list <- lapply(behav_vars, function(x) func_process_mod_brm(variable = x))
names(fitted_process_brm_list) <- behav_vars

# note that each item in the list is, itself, a list. If you want to get the first element of each list (pop_posterior), you can go lapply(fitted_process_brm_list, function(x) x[[1]])
```

\#\#\#Plotting

```{r}

# Function to plot fitted vs. predicted and calculate R2
func_fit_pred_plots_brms <- function(df1 = fitted_process_brm_list[[2]]){
  
  behav<- gsub(".*dur\\_|.*dist\\_", "", df1[[2]]$variable_name[1]) 
  
  R2<- cor(df1[[2]]$fitted, df1[[2]]$predicted)^2 %>% round(3)
  
  plot<- ggplot(df1[[2]])+
    theme_classic()+
    geom_point(aes(x=fitted, y=predicted, color='brms'))+ #
    theme(legend.position = "none")+
    labs(x=df1[[2]]$variable_name[1],
         title=behav,subtitle=paste0("R2 = ", R2))
  
  return(plot)
}

plot_list_behavs_brms <- lapply(fitted_process_brm_list, function(x) func_fit_pred_plots_brms(x))

plot_list_behavs_brms[[1]]
plot_list_behavs_brms[[2]]
plot_list_behavs_brms[[3]]
plot_list_behavs_brms[[4]]
plot_list_behavs_brms[[5]]


```

\#\#\#Repeatability of BRM models

```{r}
# TASK TWO: calculate repeatability for all behaviors from the brm models. 

 func_var_rpt_brms <- function(variable = behav_vars[1]){
    mod <- fitted_process_brm_list[[variable]]
    
   post <-  mod[[1]]
    names(post)
    indiv_var <- post$sigma_ID^2
    resid_var <- post$sigma_e^2
    total_var <- indiv_var + resid_var
    rpt <- indiv_var/total_var
    mean_rpt <- mean(rpt) #mean repeatability
    ci.lb <- quantile(rpt,0.025) 
    ci.ub <- quantile(rpt, 0.975) 
    #95% CI
   df2 <- data.frame(variable, mean_rpt, ci.lb, ci.ub, rpt)
    return(df2)
 }
 
fitted_process_brm_list_rpt <- lapply(behav_vars, function(x) func_var_rpt_brms(variable = x)) 
names(fitted_process_brm_list_rpt) <- behav_vars

fitted_process_brm_list_rpt


# Function to plot repeatability estimates

df= fitted_process_brm_list_rpt[[1]]



rpt_density_plot <- function(df){p <- ggplot()+
  theme_classic()+
  geom_density(data = df, aes(x=rpt))+
  labs(title=df$variable[1], x= "repeatability")+
  scale_y_continuous(expand=c(0,0))+
  scale_x_continuous(expand=c(0,0), breaks=seq(0,0.5,0.1), lim= c(0,0.5))+
  geom_vline(xintercept = df$mean_rpt[1])+
  geom_rect(data = df, aes(xmin = ci.lb[1], xmax = ci.ub[1], ymin=0, ymax=7), alpha=0.005)
return(p)}

rpt_plots <- lapply(fitted_process_brm_list_rpt, function(x) rpt_density_plot(x))

plot_grid(plotlist = rpt_plots)
```
###Plotting population effects

$$y_{ij} = \beta_0 + \text{ID}_j + \beta_1(\text{treatment})+ \beta_2(\text{male}) + \beta_3(\text{treatment}\cdot\text{male}) + e_i$$

$$\text{ID} \sim \text{N}(0,\sigma^2_{\text{ID}})$$

$$e \sim \text{N}(0,\sigma^2_{\text{e}})$$

```{r}


func_pop <- function(variable = behav_vars[1]){
    mod <- fitted_process_brm_list[[variable]]
    
   post <-  mod[[1]]
    names(post)
    control_female <- post$b0
    treatment_female_minus_control_female <- post$b1 
    treatment_female <- post$b1 + control_female
    control_male_minus_control_female <- post$b2
    control_male <- post$b2 + control_female
    treatment_male <- post$b0 + post$b1 + post$b2 + post$b3
    treatment_male_minus_treatment_female <- treatment_male - treatment_female
    treatment_male_minus_control_male <- treatment_male - control_male
df_pop <- data.frame (control_female,treatment_female,treatment_female_minus_control_female,control_male,treatment_male,control_male_minus_control_female,treatment_male_minus_control_male, treatment_male_minus_treatment_female)

str(df_pop)
data <- cbind(
    apply(df_pop,2,function(x) mean(x)),
    apply(df_pop, 2, function(x) quantile(x, 0.025)),
    apply(df_pop, 2, function(x) quantile(x, 0.975))
) %>% as.data.frame()

names(data) <- c("mean.post", "ci.lb", "ci.ub")
data$coef <- (row.names(data))
data$variable <- variable
data$coef <- factor(data$coef, levels = c("control_female", "treatment_female", "control_male", "treatment_male","treatment_female_minus_control_female", "treatment_male_minus_control_male", "control_male_minus_control_female", "treatment_male_minus_treatment_female"))
    
   return(data)
}

fitted_process_brm_list_pop <- lapply(behav_vars, function(x) func_pop(variable = x)) 
names(fitted_process_brm_list_pop) <- behav_vars

fitted_process_brm_list_pop

d<- fitted_process_brm_list_pop[[1]]

#Attempt at doing basic forest plots (use geom_pointrange !!! Takes x, ymin, ymax and y to make the points and errorbar in one go; one of the arguements for making the point bigger without the line getting "fatten=5")

func_forest_plots <- function (variable = behav_vars[1]){
    mod <- fitted_process_brm_list_pop[[variable]]
    
   post <-  mod
    names(post)
forest <-
  ggplot(post,
         aes(x = coef, y = mean.post)) + 
  geom_errorbar(
    aes(ymin = ci.lb, ymax = ci.ub),
    width = 0.4,
    position = position_dodge(0.3),
    size = 0.8)+
  coord_flip()+
  geom_point(aes(x = coef, y = mean.post), 
             position = position_dodge(0.3),
             size = 3) 
return(forest)
}

forest_plots_pop <- lapply(behav_vars, function(x) func_forest_plots(variable = x)) 

names(forest_plots_pop) <- behav_vars

forest_plots_pop[1]
forest_plots_pop[2]
forest_plots_pop[3]
forest_plots_pop[4]
forest_plots_pop[5]

```

\#Function for Bivar Models and Dataframe

```{r}
#Function for running the bivar model 



bivar_model <- function(var1,var2, df = Personality_wide){
  df$response1 <- df[,var1]
  df$response2 <- df[,var2]
formula1 <- bf(response1 ~ Group*Sex + (1 | 2 |Fish_ID))
formula2 <- bf(response2 ~ Group*Sex + (1 | 2 |Fish_ID))
bivar_formula <- mvbrmsformula(formula1, formula2)
bivar <- brm(formula = bivar_formula,
                     data = df,
                     family = gaussian(),
                     chains = 1,
                     iter = 2000, warmup = 1000)
return(bivar)
}





# formula1 <- bf(zone_05_dur_Social ~ Group*Sex + (1 | 2 |Fish_ID))
# formula2 <- bf(zone_05_dur_Predator ~ Group*Sex + (1 | 2 |Fish_ID))
# bivar_formula <- mvbrmsformula(formula1, formula2)
# example_Social_Predator <- brm(formula = bivar_formula,
#                      data = Personality_wide,
#                      family = gaussian(),
#                      chains = 1,#note this is just a test model that we need to run fast, real should have more chains
#                      iter = 2000, warmup = 1000)#and more iterations and more warmup
# save(example_Social_Predator, file = "./Models/example_bivar.Rdata")

load("./Models/example_bivar.Rdata")


#Function to handle bivariate model outputs
mod_char




Combinations <- combn(behav_vars,2) # To see the combinations required for the bivariate models


# Combinations required for bivar models

# Social Predator
# Social Novel
# Social Aggression
# Social Activity
# Aggression Novel
# Aggression Predator
# Aggression Activity
# Novel Predator
# Novel Activity
# Predator Activity
```
#Bivariate models and dataframes

```{r}

#Social Predator Bivariate Model

example_Social_Predator <- bivar_model("zone_05_dur_Social", "zone_05_dur_Predator")
save(example_Social_Predator, file = "./Models/social_predator_bivar.Rdata")


social_predator_bivar <- bivar_brm_func("example_Social_Predator")

#Social_Novel Bivariate model

example_Social_Novel <- bivar_model("zone_05_dur_Social", "zone_05_dur_Novel")
save(example_Social_Novel, file = "./Models/social_novel_bivar.Rdata")


social_novel_bivar <- bivar_brm_func("example_Social_Novel")


#Social_Aggression Bivariate model

example_Social_Aggression <- bivar_model("zone_05_dur_Social", "zone_05_dur_Aggression")
save(example_Social_Aggression, file = "./Models/social_aggression_bivar.Rdata")


social_aggression_bivar <- bivar_brm_func("example_Social_Aggression")




#Social_Activity Bivariate Model

example_Social_Activity <- bivar_model("zone_05_dur_Social", "tot_dist_Activity")
save(example_Social_Activity, file = "./Models/social_activity_bivar.Rdata")


social_activity_bivar <- bivar_brm_func("example_Social_Activity")


#Agression Novel Bivariate Model

example_Aggression_Novel <- bivar_model("zone_05_dur_Aggression", "zone_05_dur_Novel")
save(example_Aggression_Novel, file = "./Models/aggression_novel_bivar.Rdata")


aggression_novel_bivar <- bivar_brm_func("example_Aggression_Novel")

#Agression Predator Bivariate Model

example_Aggression_Predator <- bivar_model("zone_05_dur_Aggression", "zone_05_dur_Predator")
save(example_Aggression_Predator, file = "./Models/aggression_predator_bivar.Rdata")


aggression_predator_bivar <- bivar_brm_func("example_Aggression_Predator")


#Aggression Activity Bivariate Model

example_Aggression_Activity <- bivar_model("zone_05_dur_Aggression", "tot_dist_Activity")
save(example_Aggression_Activity, file = "./Models/aggression_activity_bivar.Rdata")

aggression_activity_bivar <- bivar_brm_func("example_Aggression_Activity")


#Novel Predator Bivariate Model

example_Novel_Predator <- bivar_model("zone_05_dur_Novel", "zone_05_dur_Predator")
save(example_Novel_Predator, file = "./Models/novel_predator_bivar.Rdata")


novel_predator_bivar <- bivar_brm_func("example_Novel_Predator")



#Novel Activity Bivariate Model

example_Novel_Activity <- bivar_model("zone_05_dur_Novel", "tot_dist_Activity")
save(example_Novel_Activity, file = "./Models/novel_activity_bivar.Rdata")

novel_activity_bivar <- bivar_brm_func("example_Novel_Activity")


#Predator Activity Bivariate Model

example_Predator_Activity <- bivar_model("zone_05_dur_Predator", "tot_dist_Activity")
save(example_Predator_Activity, file = "./Models/predator_activity_bivar.Rdata")

predator_activity_bivar <- bivar_brm_func("example_Predator_Activity")


```

#Practice I cannot remember what this chunk was for?

```{r}
bivar_combined$behav_syndrome <- paste0(bivar_combined$behaviour1, " vs. ", bivar_combined$behaviour2)

splt <- split(bivar_combined, bivar_combined$behav_syndrome)

df=splt[[1]]

sapply(3:18, function(x) mean(df[,x]))

mean_df <- apply(df[,3:18],2,function(x) mean(x))

ci.lower <- apply(df[,3:18],2, function(x) quantile(x, 0.025))

ci.upper <- apply(df[,3:18],2, function(x) quantile(x, 0.975))

test_df_plot <- data.frame(mean_df,ci.lower,ci.upper)

row.names(test_df_plot)

test_df_plot$param <- row.names(test_df_plot)

test_df_plot$behav_syndrome <- df$behav_syndrome[1]

#I can't remember what this chunk was for, I remmeber you said I will need to do this for something, can't remember what

```

Example plots and tables

```{r}

#Creating multiple plots and subsetting to remove contrasts
ggplot(subset(bivar_behavs_results,coef %in% c("treatment_male", "control_male", "treatment_female", "control_female"))) + 
geom_pointrange(mapping=aes(x=coef, y=mean.post, ymin=ci.lb, ymax=ci.ub, color=behavior))+
  coord_flip()+
  facet_wrap(~behavior, scales = "free_x")
#Issues with error bars though :/ Some of the ranges are too small too see

#tab_model() in sJplot actually can create html tables from Bayesian outputs, which can be exported into an html file and then copied and edited manually in word; however this doesn't include correlation analysis :/ however I can add this information manually in word, not sure how else to create a table output atm :/

tab_model(example_Social_Aggression, show.hdi50 = FALSE, bpe = "mean") #bpe calculates mean of posterior, otherwise would be median


```

#Tables - importing

```{r}
t1 <- read_excel("Table1.xlsx", sheet = "Table 1", skip = 2)

#Note: We going to use bivar_behavs_results to get our results for the table, we need to find information in right order to import into table

#which coef do we want? See order:

# female control
# female treatment
# male control
# male treatment
# treatment - control (female)
# treatment - control (male)
# male - female (control)
# male - female (treatment)

#ROSE R LESSON ! INDEXING
unique(bivar_behavs_results$coef)

coef_names <- c("control_female", "treatment_female", "control_male", "treatment_male", "treatment_female_minus_control_female", "treatment_male_minus_control_male", "control_male_minus_control_female", "treatment_male_minus_treatment_female")

df <- bivar_behavs_results[bivar_behavs_results$behavior=="Activity",]

x=coef_names[1]

df[df$coef==x,c("mean.post", "ci.lb", "ci.ub")]

lapply(coef_names, function(x) df[df$coef==x,c("mean.post", "ci.lb", "ci.ub")])

table_example <- bind_rows(lapply(coef_names, function(x) df[df$coef==x,c("mean.post", "ci.lb", "ci.ub")])) 

t1[2:9,3:5] <- round(table_example, 3)

dim(table_example)

dim(t1[2:9,3:5])

write.csv(t1, file="t1.csv", row.names=FALSE, na="")

# 
# df[c(2,6),]
# 
# which(bivar_behavs_results$behavior=="Activity")

```

```{r}
# ROSE: alternative
contrasts1 <- contrasts_var[,c("behaviour1",
                 "sigma_ID1_treatment_minus_control",
                 "sigma_e1_treatment_minus_control",
                 "rpt1_treatment_minus_control")]
contrasts2 <- contrasts_var[,c("behaviour2",
                 "sigma_ID2_treatment_minus_control",
                 "sigma_e2_treatment_minus_control",
                 "rpt2_treatment_minus_control")]
names(contrasts1) <- gsub("1","",names(contrasts1))
names(contrasts2) <- gsub("2","",names(contrasts2))
Rpt_behav_contrasts <- rbind(contrasts1, contrasts2) %>% dplyr::arrange(behaviour)

Rpt_behav_contrasts %>% dplyr::group_by(behaviour) %>% 
  dplyr::summarise(is.numeric, mean)

var_contrasts_est <- dplyr::bind_rows(lapply(split(Rpt_behav_contrasts, Rpt_behav_contrasts$behaviour),
      function(x)
        func(x))) 

func <- function(df){
  
  est <- apply(df[,2:4], 2, function(x) mean(x))
  lb <- apply(df[,2:4], 2, function(x) quantile(x, 0.025))
  ub <- apply(df[,2:4], 2, function(x) quantile(x, 0.975))
  
  names(est) <- paste0(names(est), ".est")
  names(lb) <- paste0(names(est), ".lb")
  names(ub) <- paste0(names(est), ".ub")
  df2 <- data.frame(cbind(est, lb, ub))
  df2$parameter <- gsub("\\.est", "", rownames(df2))
  df2$behaviour <- df[1,1]
  return(df2)
  
}

#for rprt contrasts
```

Using Shapiro-Wilk normality test\
See ?shapiro.test More normal = higher W value and smaller p value

```{r}
func_behav_raw <- function(behav = behavs[1]){
  
  func_var <- function(var = vars[1]){
    mod <- lmer(Personality_wide[,paste(var,behav,sep="_")] ~ Group*Sex + (1 | Fish_ID), data = Personality_wide) 
    residuals <- resid(mod)
    VC <- data.frame(VarCorr(mod))
    rpt <- round(VC$vcov[1]/sum(VC$vcov),2)
    sw <- shapiro.test(residuals)
    df <- data.frame(behav, var, rpt, W = round(sw$statistic,3), p = round(sw$p.value,3))
    return(df)
  } # raw general linear model to determine whether transformations are required
  

  
 rpt_vals <- bind_rows(lapply(vars, function(x) func_var(x)))
 return(rpt_vals)
}

func_behav_sqrt <- function(behav = behavs[1]){
  
  func_var <- function(var = vars[1]){
    mod <- lmer(sqrt(Personality_wide[,paste(var,behav,sep="_")]) ~ Group*Sex + (1 | Fish_ID), data = Personality_wide) # added a square root transformation here to the model
    residuals <- resid(mod)
    VC <- data.frame(VarCorr(mod))
    rpt <- round(VC$vcov[1]/sum(VC$vcov),2)
    sw <- shapiro.test(residuals)
    df <- data.frame(behav, var, rpt, W = round(sw$statistic,3), p = round(sw$p.value,3))
    return(df)
  } # same general linear model as above but with a square root transformation
  

  
 rpt_vals <- bind_rows(lapply(vars, function(x) func_var(x)))
 return(rpt_vals)
}

# RUNNING MODELS 

rpt_resids <- bind_rows(lapply(behavs, function(x) func_behav_raw(x))) # not transformed

rpt_resids_sqrt <- bind_rows(lapply(behavs, function(x) func_behav_sqrt(x))) # sqrt transformed

# CHECKING TO SEE WHICH VARIABLES ARE NORMAL AND WHICH REQUIRE TRANSFORMATION

# restricting to just values of W > 0.9 and seeing which variables are represented for all behaviors

rpt_resids %>% filter(W>0.9) %>% group_by(var) %>% tally()


# only mean_speed and tot_dist are there for everything


filter(rpt_resids, var == "mean_speed") # all looks good, except p-val for Aggression?

filter(rpt_resids, var == "tot_dist") # similar to above?

# zone_near_dur there for 4/5, so we want to check which phase would need to be transformed 

filter(rpt_resids, var == "zone_near_dur") 

#this shows that the "Social" phase needs a transformation for the variable zone_near_dur, so we'll see if a square root transformation helps

rpt_resids_sqrt %>% filter(W>0.9) %>% group_by(var) %>% tally()

filter(rpt_resids_sqrt, var == "zone_near_dur")

# The square root transformation doesn't help for the variable zone_near_dur for the Social phase, so will try to identify another variable that can be used for all 5 phases as long as transformations work

rpt_resids %>% filter(W>0.9) %>% group_by(var) %>% tally()

#Will try to see tot_dist_05
 
filter(rpt_resids, var == "tot_dist_05")

#Social and Aggression require transformations, will see if the sqrt transformations helped

filter(rpt_resids_sqrt, var == "tot_dist_05")

#Aggression phase is good with a square root transformation, Social phase improved, possibility it can be used?

# Will now check zone_05_dur

filter(rpt_resids, var == "zone_05_dur")

#Not too fussed with Activity phase as we will use a distance variable, however, Novel phase needs to be transformed. Will see if the transformation helps with normality

filter(rpt_resids_sqrt, var == "zone_05_dur")

#A square root transformation appears to have done the job.

# To summarize, we can use the following variables for analysis

# Mean speed (all 5 phases), total distance (all 5 phases), zone_05_dur (Novel phases requires a square root transformation)
```

### Residual distributions and repeatability values for each variable




#Plotting density distributions

```{r}
bivar_combined$behav_syndrome <- paste0(bivar_combined$behaviour1, " vs. ", bivar_combined$behaviour2)

col_behav_syndrome <- bivar_combined$behav_syndrome 
unique(col_behav_syndrome, incomparables = FALSE)



Aggression_Activity <- subset(bivar_combined, bivar_combined$behav_syndrome == "Aggression vs. Activity")
Aggression_Novel <- subset(bivar_combined, bivar_combined$behav_syndrome == "Aggression vs. Novel")
Aggression_Predator <- subset(bivar_combined, bivar_combined$behav_syndrome == "Aggression vs. Predator")
Novel_Activity <- subset(bivar_combined, bivar_combined$behav_syndrome == "Novel vs. Activity")
Novel_Predator <- subset(bivar_combined, bivar_combined$behav_syndrome == "Novel vs. Predator")
Predator_Activity <- subset(bivar_combined, bivar_combined$behav_syndrome == "Predator vs. Activity")
Social_Activity <- subset(bivar_combined, bivar_combined$behav_syndrome == "Social vs. Activity")
Social_Aggression <- subset(bivar_combined, bivar_combined$behav_syndrome == "Social vs. Aggression")
Social_Novel <- subset(bivar_combined, bivar_combined$behav_syndrome == "Social vs. Novel")
Social_Predator <- subset(bivar_combined, bivar_combined$behav_syndrome == "Social vs. Predator")

behav_syndromes <- list(Aggression_Activity,Aggression_Novel, Aggression_Predator,Novel_Activity,Novel_Predator, Predator_Activity ,Social_Activity, Social_Aggression, Social_Novel,Social_Predator)

density_plot_bivar <- function(df){
  heading = df$behav_syndrome
plot <- ggplot(df) + 
  theme_classic() +
  geom_density(aes(cor_ID1_ID2)) +
  geom_vline(xintercept = 0, color = "red") +
  geom_vline(xintercept = mean(df$cor_ID1_ID2),col="black",lwd=2) +
  geom_vline(xintercept = HPDinterval(as.mcmc(df$cor_ID1_ID2))[1],col="black",lty=2)+
  geom_vline(xintercept = HPDinterval(as.mcmc(df$cor_ID1_ID2))[2],col="black",lty=2)+
  labs(title = heading)
  return(plot)
}


bivar_density_plots <- lapply(behav_syndromes, function(x) density_plot_bivar(x)) #applying function to all bivar model outputs
names(bivar_density_plots) <- behav_syndromes #naming the elements of the list

bivar_density_plots


```
